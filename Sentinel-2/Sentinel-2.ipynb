{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc60d36-877c-4598-a728-4860c8c6c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, shlex, subprocess\n",
    "import os, subprocess\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from __future__ import annotations\n",
    "import numpy as np, csv\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.windows import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef4e0a2-4529-4bd0-b91f-03df76d4b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CFG] PLOT=Teruel | TILE=T30TXK | YEAR=2022 | REGION_TAG=Teruel | ORBIT=None | EPSG=EPSG:25830 | MODE=release\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 0: GLOBAL CONFIG (keeps your original names) =====\n",
    "\n",
    "# --- Edit these per run ---\n",
    "PLOT = \"Teruel\"\n",
    "TILE = \"T30TXK\"\n",
    "YEAR = \"2022\"\n",
    "\n",
    "# Region tag (unchanged logic)\n",
    "REGION_TAG = {\n",
    "    \"Lousa\": \"SerraLousa\",\n",
    "    \"Mafra\": \"SerraMafra\",\n",
    "    \"Monsanto\": \"SerraMonsanto\",\n",
    "    \"Pombal\": \"SerraPombal\",\n",
    "    \"Sintra\": \"SerraSintra\",\n",
    "    \"VPA\": \"SerraVPA\",\n",
    "    # Spain examples:\n",
    "    \"Extremadura\": \"Extremadura\",\n",
    "    \"Leon\": \"Leon\",\n",
    "    \"Huesca\": \"Huesca\",\n",
    "    \"Zaragoza\": \"Zaragoza\",\n",
    "    \"Teruel\": \"Teruel\"\n",
    "}.get(PLOT, PLOT)\n",
    "\n",
    "# --- Paths (same names you already use) ---\n",
    "GPT_EXE   = r\"C:\\Program Files\\esa-snap\\bin\\gpt.exe\"\n",
    "GRAPH_XML = None  # set in the cell that needs it\n",
    "MEM_GB    = 8\n",
    "WORK  = Path(r\"A:\\S2\\work\") / PLOT / TILE\n",
    "DELIV = Path(r\"A:\\S2\\Deliverables\") / REGION_TAG / TILE\n",
    "WORK.mkdir(parents=True, exist_ok=True)\n",
    "DELIV.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_RES= 25\n",
    "BAD_DATES = set() \n",
    "\n",
    "# For clipping downstream, AOI can be used\n",
    "AOI = None\n",
    "# AOI = Path(r\"A:\\S2\\Shapefiles\\Monsanto_limite.shp\")\n",
    "# If computing stats and your AOI has multiple features:\n",
    "PER_FEATURE = False  # False = dissolve all features (one row per variable). True = one row per feature+var.\n",
    "\n",
    "# ✅ Keep your original input roots:\n",
    "EXTRACTED_ROOT = Path(r\"A:\\S2\\SAFE\") / PLOT\n",
    "ZIPPED_ROOT    = Path(r\"M:\\Project BLS\\S2\\Data\\Aragon\") / PLOT / YEAR\n",
    "# (If you switch campaign later, only change the single ZIPPED_ROOT line above)\n",
    "\n",
    "# --- CRS, resampling, nodata (shared across cells) ---\n",
    "TARGET_EPSG       = \"EPSG:3763\" if REGION_TAG.lower().startswith(\"serra\") else \"EPSG:25830\"\n",
    "RESAMPLE_NUMERIC = \"bilinear\"  # numeric/continuous\n",
    "RESAMPLE_FLAGS   = \"near\"      # flags / discrete masks\n",
    "PLATFORM          = \"S2\"\n",
    "\n",
    "# --- Orbit preference (None means “don’t filter”) ---\n",
    "ORBIT = {\n",
    "    \"SerraMonsanto\": \"R037\",\n",
    "    \"SerraSintra\":   \"R037\",\n",
    "    \"SerraMafra\":    \"R037\",\n",
    "    # \"Extremadura\": None,\n",
    "    # \"Leon\": None,\n",
    "}.get(REGION_TAG, None)\n",
    "\n",
    "# --- Naming helpers (same you already call) ---\n",
    "def fmt_tag(region: str, year: str, dataset: str, tile: str) -> str:\n",
    "    return f\"{region}_{year}0000_{dataset}_{tile}\"\n",
    "\n",
    "def out_name(study_area: str, year: str, platform: str, variable: str, tile: str) -> str:\n",
    "    # StudyArea_YYYY0000_Platform_Variable_Tile.tif\n",
    "    return f\"{study_area}_{year}0000_{platform}_{variable}_{tile}.tif\"\n",
    "\n",
    "# --- Lightweight shell helpers you already use ---\n",
    "def run(cmd: str):\n",
    "    print(\">>\", cmd)\n",
    "    p = subprocess.run(cmd, shell=True, text=True, capture_output=True)\n",
    "    if p.stdout.strip(): print(p.stdout.strip())\n",
    "    if p.returncode != 0:\n",
    "        if p.stderr.strip(): print(p.stderr.strip())\n",
    "        raise RuntimeError(\"Command failed\")\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p = Path(p)\n",
    "    (p.parent if p.suffix else p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Common subfolders you already reference ---\n",
    "\n",
    "WORK  = Path(r\"A:\\S2\\work\") / PLOT / TILE\n",
    "DELIV = Path(r\"A:\\S2\\Deliverables\") / PLOT / TILE\n",
    "DELIV.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "COMPOSITE_DIR = WORK / \"COMPOSITE25\"\n",
    "GLCM_DIR      = WORK / \"GLCM25\"\n",
    "REF_DIR       = WORK / \"REF25\"\n",
    "BIO_DIR       = WORK / \"BIO25\"\n",
    "SCL_DIR       = WORK / \"SCL25\"\n",
    "for d in (REF_DIR, BIO_DIR, SCL_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "D_S2TC = DELIV / \"S2TC\"\n",
    "D_BIO  = DELIV / \"BIO\"\n",
    "D_GLCM = DELIV / \"GLCM\"\n",
    "for d in (WORK, DELIV, D_S2TC, D_BIO, D_GLCM):\n",
    "    ensure_dir(d)\n",
    "\n",
    "# --- Band maps (same names you already wired into the builder/README) ---\n",
    "REF_BANDS = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]  # SNAP preprocessing\n",
    "TC_BANDS  = [f\"{b}_TC\" for b in REF_BANDS] #SNAP TC + GLCM\n",
    "\n",
    "NODATA = -9999\n",
    "\n",
    "# GLCM stat order (no 'GLCM' prefix in output filenames)\n",
    "GLCM_STATS = [\"CONTRAST\",\"DISSIMILARITY\",\"HOMOGENEITY\",\"ASM\",\"ENERGY\",\n",
    "              \"MAX\",\"ENTROPY\",\"GLCMMEAN\",\"GLCMVARIANCE\",\"GLCMCORRELATION\"]\n",
    "\n",
    "# TC band labels in order (12)\n",
    "TC_DATASET_ORDER = [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B11\",\"B12\"] #GDAL dataset semantics\n",
    "\n",
    "# BIO maps\n",
    "BIO_TC_ORDER = [\"LAI\",\"FAPAR\",\"FCOVER\",\"CAB\",\"CWC\"]  # 5-band temporal composite\n",
    "BIO_DT_ORDER = [\"LAI\",\"LAI_FLAGS\",\"CAB\",\"CAB_FLAGS\",\"CWC\",\"CWC_FLAGS\",\n",
    "                \"FAPAR\",\"FAPAR_FLAGS\",\"FCOVER\",\"FCOVER_FLAGS\"]  # per-date (10)\n",
    "\n",
    "# --- Publisher mode (optional, same idea; rest of code can read this) ---\n",
    "PUBLISH_MODE = \"release\"  # \"dev\" | \"release\"\n",
    "def publisher_policy():\n",
    "    keep = {\n",
    "        \"dev\":     {\"WORK\", \"S2TC\", \"BIO\", \"GLCM\", \"DATASET\", \"QA\", \"README\", \"INVENTORY\"},\n",
    "        \"release\": {\"DATASET\", \"QA\", \"README\", \"INVENTORY\"},\n",
    "    }[PUBLISH_MODE]\n",
    "    return keep\n",
    "\n",
    "print(f\"[CFG] PLOT={PLOT} | TILE={TILE} | YEAR={YEAR} | REGION_TAG={REGION_TAG} | ORBIT={ORBIT} | EPSG={TARGET_EPSG} | MODE={PUBLISH_MODE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3e4648e-4f64-4f5b-8e59-571ed01ac4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   raw candidates for Teruel/T30TXK: 6\n",
      "     S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011.SAFE.zip orbit= R051\n",
      "     S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140.SAFE.zip orbit= R051\n",
      "     S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845.SAFE.zip orbit= R051\n",
      "     S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133.SAFE.zip orbit= R051\n",
      "     S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405.SAFE.zip orbit= R051\n",
      "     S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157.SAFE.zip orbit= R051\n",
      "Found 6 S2 L2A inputs for Teruel/T30TXK\n",
      "  - M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\May\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133.SAFE.zip   (date=20220515)\n",
      "  - M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\June\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845.SAFE.zip   (date=20220619)\n",
      "  - M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\July\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140.SAFE.zip   (date=20220724)\n",
      "  - M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\August\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011.SAFE.zip   (date=20220828)\n",
      "  - M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\September\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157.SAFE.zip   (date=20220927)\n",
      "  - M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\October\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405.SAFE.zip   (date=20221002)\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_SplitRef_Bio_SCL.xml' '-PinFile=M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\May\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133.SAFE.zip' '-PoutRef=A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_REF25.dim' '-PoutBio=A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_BIO25.dim' '-PoutScl=A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_SCL25.dim' -PtargetRes=25 -Psensor=S2B -c 8G\n",
      "Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "   ✓ wrote\n",
      "     REF: A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_REF25.dim\n",
      "     BIO: A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_BIO25.dim\n",
      "     SCL: A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_SCL25.dim  (15.2 min)\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_SplitRef_Bio_SCL.xml' '-PinFile=M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\June\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845.SAFE.zip' '-PoutRef=A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_REF25.dim' '-PoutBio=A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_BIO25.dim' '-PoutScl=A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_SCL25.dim' -PtargetRes=25 -Psensor=S2A -c 8G\n",
      "Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "   ✓ wrote\n",
      "     REF: A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_REF25.dim\n",
      "     BIO: A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_BIO25.dim\n",
      "     SCL: A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_SCL25.dim  (18.5 min)\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_SplitRef_Bio_SCL.xml' '-PinFile=M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\July\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140.SAFE.zip' '-PoutRef=A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_REF25.dim' '-PoutBio=A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_BIO25.dim' '-PoutScl=A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_SCL25.dim' -PtargetRes=25 -Psensor=S2B -c 8G\n",
      "Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "   ✓ wrote\n",
      "     REF: A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_REF25.dim\n",
      "     BIO: A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_BIO25.dim\n",
      "     SCL: A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_SCL25.dim  (14.2 min)\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_SplitRef_Bio_SCL.xml' '-PinFile=M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\August\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011.SAFE.zip' '-PoutRef=A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_REF25.dim' '-PoutBio=A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_BIO25.dim' '-PoutScl=A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_SCL25.dim' -PtargetRes=25 -Psensor=S2A -c 8G\n",
      "Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "   ✓ wrote\n",
      "     REF: A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_REF25.dim\n",
      "     BIO: A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_BIO25.dim\n",
      "     SCL: A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_SCL25.dim  (15.9 min)\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_SplitRef_Bio_SCL.xml' '-PinFile=M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\September\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157.SAFE.zip' '-PoutRef=A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_REF25.dim' '-PoutBio=A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_BIO25.dim' '-PoutScl=A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_SCL25.dim' -PtargetRes=25 -Psensor=S2A -c 8G\n",
      "Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "   ✓ wrote\n",
      "     REF: A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_REF25.dim\n",
      "     BIO: A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_BIO25.dim\n",
      "     SCL: A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_SCL25.dim  (16.3 min)\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_SplitRef_Bio_SCL.xml' '-PinFile=M:\\Project BLS\\S2\\Data\\Aragon\\Teruel\\2022\\October\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405.SAFE.zip' '-PoutRef=A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_REF25.dim' '-PoutBio=A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_BIO25.dim' '-PoutScl=A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_SCL25.dim' -PtargetRes=25 -Psensor=S2B -c 8G\n",
      "Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "   ✓ wrote\n",
      "     REF: A:\\S2\\work\\Teruel\\T30TXK\\REF25\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_REF25.dim\n",
      "     BIO: A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_BIO25.dim\n",
      "     SCL: A:\\S2\\work\\Teruel\\T30TXK\\SCL25\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_SCL25.dim  (13.4 min)\n",
      "\n",
      "Done. Success: 6  Failures: 0\n",
      "REF25: 6  BIO25: 6  SCL25: 6\n"
     ]
    }
   ],
   "source": [
    "# === Extract reflectance, biophysical, and scene classification and resample (SAFE or SAFE.zip) ===\n",
    "\n",
    "# --- CONFIG ---\n",
    "GRAPH_XML_TEXT = r\"\"\"<graph id=\"S2_SplitRef_Bio_SCL\">\n",
    "  <version>1.0</version>\n",
    "\n",
    "  <node id=\"Read\">\n",
    "    <operator>Read</operator>\n",
    "    <sources/>\n",
    "    <parameters><file>${inFile}</file></parameters>\n",
    "  </node>\n",
    "\n",
    "  <!-- Branch A: Biophysical fast (Nearest/Median @ targetRes) -->\n",
    "  <node id=\"Resample_For_Bio\">\n",
    "    <operator>Resample</operator>\n",
    "    <sources><sourceProduct refid=\"Read\"/></sources>\n",
    "    <parameters>\n",
    "      <targetResolution>${targetRes}</targetResolution>\n",
    "      <upsampling>Nearest</upsampling>\n",
    "      <downsampling>Median</downsampling>\n",
    "    </parameters>\n",
    "  </node>\n",
    "\n",
    "  <node id=\"BiophysicalOp\">\n",
    "    <operator>BiophysicalOp</operator>\n",
    "    <sources>\n",
    "      <sourceProduct refid=\"Resample_For_Bio\"/>\n",
    "    </sources>\n",
    "    <parameters>\n",
    "      <sensor>${sensor}</sensor>\n",
    "      <resolution>20</resolution>\n",
    "      <computeLAI>true</computeLAI>\n",
    "      <computeFapar>true</computeFapar>\n",
    "      <computeFcover>true</computeFcover>\n",
    "      <computeCab>true</computeCab>\n",
    "      <computeCw>true</computeCw>\n",
    "    </parameters>\n",
    "  </node>\n",
    "\n",
    "  <node id=\"Write_Bio\">\n",
    "    <operator>Write</operator>\n",
    "    <sources><sourceProduct refid=\"BiophysicalOp\"/></sources>\n",
    "    <parameters><file>${outBio}</file></parameters>\n",
    "  </node>\n",
    "\n",
    "  <!-- Branch B: Reflectance (Bicubic/Median @ targetRes), subset to B1..B12 except B10 -->\n",
    "  <node id=\"Subset_Reflectance\">\n",
    "    <operator>Subset</operator>\n",
    "    <sources><sourceProduct refid=\"Read\"/></sources>\n",
    "    <parameters>\n",
    "      <sourceBands>B1,B2,B3,B4,B5,B6,B7,B8,B8A,B9,B11,B12</sourceBands>\n",
    "      <copyMetadata>true</copyMetadata>\n",
    "    </parameters>\n",
    "  </node>\n",
    "\n",
    "  <node id=\"Resample_Reflectance\">\n",
    "    <operator>Resample</operator>\n",
    "    <sources><sourceProduct refid=\"Subset_Reflectance\"/></sources>\n",
    "    <parameters>\n",
    "      <targetResolution>${targetRes}</targetResolution>\n",
    "      <upsampling>Bicubic</upsampling>\n",
    "      <downsampling>Median</downsampling>\n",
    "    </parameters>\n",
    "  </node>\n",
    "\n",
    "  <node id=\"Write_Ref\">\n",
    "    <operator>Write</operator>\n",
    "    <sources><sourceProduct refid=\"Resample_Reflectance\"/></sources>\n",
    "    <parameters><file>${outRef}</file></parameters>\n",
    "  </node>\n",
    "\n",
    "  <!-- Branch C: SCL (quality_scene_classification) @ targetRes for masking -->\n",
    "  <node id=\"Subset_SCL\">\n",
    "    <operator>Subset</operator>\n",
    "    <sources><sourceProduct refid=\"Read\"/></sources>\n",
    "    <parameters>\n",
    "      <sourceBands>quality_scene_classification</sourceBands>\n",
    "      <copyMetadata>true</copyMetadata>\n",
    "    </parameters>\n",
    "  </node>\n",
    "\n",
    "  <node id=\"Resample_SCL\">\n",
    "    <operator>Resample</operator>\n",
    "    <sources><sourceProduct refid=\"Subset_SCL\"/></sources>\n",
    "    <parameters>\n",
    "      <targetResolution>${targetRes}</targetResolution>\n",
    "      <upsampling>Nearest</upsampling>\n",
    "      <downsampling>Median</downsampling>\n",
    "    </parameters>\n",
    "  </node>\n",
    "\n",
    "  <node id=\"Write_SCL\">\n",
    "    <operator>Write</operator>\n",
    "    <sources><sourceProduct refid=\"Resample_SCL\"/></sources>\n",
    "    <parameters><file>${outScl}</file></parameters>\n",
    "  </node>\n",
    "</graph>\n",
    "\"\"\"\n",
    "\n",
    "# --- HELPERS ---\n",
    "RE_DATE = re.compile(r\"(\\d{8})T\\d{6}\")\n",
    "RE_TILE = re.compile(r\"(T\\d{2}[A-Z]{3})\")\n",
    "\n",
    "def want_tile(name: str, tile_code: str) -> bool:\n",
    "    mt = RE_TILE.search(name)\n",
    "    return (mt and mt.group(1) == tile_code)\n",
    "\n",
    "def fmt_tag(region: str, year: str, dataset: str, tile: str) -> str:\n",
    "    return f\"{region}_{year}0000_{dataset}_{tile}\"\n",
    "\n",
    "def acq_date_from_path(p: Path) -> str:\n",
    "    \"\"\"Extract acquisition date from SAFE/SAFE.zip or MTD file.\"\"\"\n",
    "    name_for_date = p.parent.name if p.name == \"MTD_MSIL2A.xml\" else p.name\n",
    "    m = RE_DATE.search(name_for_date)\n",
    "    return m.group(1) if m else \"unknown\"\n",
    "\n",
    "def safe_stem_from_path(p: Path) -> str:\n",
    "    \"\"\"Return clean stem for naming outputs (no .SAFE or .SAFE.zip).\"\"\"\n",
    "    if p.name == \"MTD_MSIL2A.xml\":\n",
    "        return p.parent.name.replace(\".SAFE\", \"\")\n",
    "    name = p.name\n",
    "    if name.endswith(\".SAFE.zip\"):\n",
    "        return name.replace(\".SAFE.zip\", \"\")\n",
    "    if name.endswith(\".SAFE\"):\n",
    "        return name.replace(\".SAFE\", \"\")\n",
    "    return name\n",
    "\n",
    "def sensor_from_stem(stem: str) -> str:\n",
    "    s = stem.upper()\n",
    "    if s.startswith(\"S2A_\"): return \"S2A\"\n",
    "    if s.startswith(\"S2B_\"): return \"S2B\"\n",
    "    return \"S2A\"  # safe default\n",
    "\n",
    "def orbit_from_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract orbit code (e.g. R037, R050, R094) from SAFE folder or zip name.\n",
    "    Returns None if not found.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"(R\\d{3})\", name)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def ensure_graph_xml(work_dir: Path, xml_text: str) -> Path:\n",
    "    \"\"\"\n",
    "    Write the SNAP graph XML to a deterministic location under WORK.\n",
    "    Returns the path to the xml file.\n",
    "    \"\"\"\n",
    "    graphs_dir = work_dir / \"_graphs\"\n",
    "    graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    xml_path = graphs_dir / \"S2_SplitRef_Bio_SCL.xml\"\n",
    "    xml_path.write_text(xml_text, encoding=\"utf-8\")\n",
    "    return xml_path\n",
    "\n",
    "def list_inputs_for_plot_tile():\n",
    "    candidates = []\n",
    "\n",
    "    # 1) extracted SAFE folders (preferred)\n",
    "    if EXTRACTED_ROOT.exists():\n",
    "        for safe_dir in sorted(EXTRACTED_ROOT.glob(\"S2*_MSIL2A_*.SAFE\")):\n",
    "            if not want_tile(safe_dir.name, TILE):\n",
    "                continue\n",
    "            mtd = safe_dir / \"MTD_MSIL2A.xml\"\n",
    "            if mtd.exists():\n",
    "                candidates.append(mtd)\n",
    "\n",
    "    # 2) zipped SAFE files (fallback, recursive under months)\n",
    "    if ZIPPED_ROOT.exists():\n",
    "        for z in sorted(ZIPPED_ROOT.rglob(\"S2*_MSIL2A_*.SAFE.zip\")):\n",
    "            if not want_tile(z.name, TILE):\n",
    "                continue\n",
    "            candidates.append(z)\n",
    "\n",
    "    if not candidates:\n",
    "        print(f\"⚠️ No inputs found for {PLOT}/{TILE}\")\n",
    "        return []\n",
    "\n",
    "    # Debug: show raw candidates + orbits\n",
    "    print(f\"   raw candidates for {PLOT}/{TILE}: {len(candidates)}\")\n",
    "    for p in candidates:\n",
    "        safe_name = p.name if p.suffix == \".zip\" else p.parent.name\n",
    "        print(\"    \", safe_name, \"orbit=\", orbit_from_name(safe_name))\n",
    "\n",
    "    # --- orbit filter ---\n",
    "    filtered = []\n",
    "    for p in candidates:\n",
    "        safe_name = p.name if p.suffix == \".zip\" else p.parent.name\n",
    "        orb = orbit_from_name(safe_name)\n",
    "        if ORBIT and orb != ORBIT:\n",
    "            continue\n",
    "        filtered.append(p)\n",
    "\n",
    "    if not filtered:\n",
    "        print(f\"⚠️ No inputs left for {PLOT}/{TILE} after orbit filter (ORBIT={ORBIT})\")\n",
    "        return []\n",
    "\n",
    "    # --- de-duplicate by acquisition date (prefer extracted) ---\n",
    "    by_date = {}\n",
    "    for p in filtered:\n",
    "        d = acq_date_from_path(p)\n",
    "\n",
    "        # ⛔️ skip known bad dates\n",
    "        if d in BAD_DATES:\n",
    "            print(f\"   • skipping bad acquisition {d} for {PLOT}/{TILE}\")\n",
    "            continue\n",
    "\n",
    "        score = 0 if p.name == \"MTD_MSIL2A.xml\" else 1  # prefer extracted\n",
    "        if d not in by_date or score < by_date[d][1]:\n",
    "            by_date[d] = (p, score)\n",
    "\n",
    "    inputs = [by_date[d][0] for d in sorted(by_date)]\n",
    "    if not inputs:\n",
    "        print(f\"⚠️ Nothing left after filters (ORBIT={ORBIT}, BAD_DATES={sorted(BAD_DATES)})\")\n",
    "    return inputs\n",
    "\n",
    "def run_one(input_path: Path):\n",
    "    stem   = safe_stem_from_path(input_path)\n",
    "    acq    = acq_date_from_path(input_path)\n",
    "    sensor = sensor_from_stem(stem)\n",
    "    graph_xml_path = ensure_graph_xml(WORK, GRAPH_XML_TEXT)\n",
    "\n",
    "\n",
    "    out_ref = REF_DIR / f\"{stem}_{acq}_{TILE}_REF{TARGET_RES}.dim\"\n",
    "    out_bio = BIO_DIR / f\"{stem}_{acq}_{TILE}_BIO{TARGET_RES}.dim\"\n",
    "    out_scl = SCL_DIR / f\"{stem}_{acq}_{TILE}_SCL{TARGET_RES}.dim\"\n",
    "\n",
    "    # skip if already exists\n",
    "    if out_ref.exists() and out_bio.exists() and out_scl.exists():\n",
    "        print(f\"   • skip (already have REF/BIO/SCL) for {stem} {acq}\")\n",
    "        return out_ref, out_bio, out_scl\n",
    "\n",
    "    cmd = [\n",
    "        GPT_EXE, str(graph_xml_path),\n",
    "        f\"-PinFile={input_path}\",\n",
    "        f\"-PoutRef={out_ref}\",\n",
    "        f\"-PoutBio={out_bio}\",\n",
    "        f\"-PoutScl={out_scl}\",\n",
    "        f\"-PtargetRes={TARGET_RES}\",\n",
    "        f\"-Psensor={sensor}\",\n",
    "        \"-c\", f\"{MEM_GB}G\"\n",
    "    ]\n",
    "    print(\">>\", \" \".join(shlex.quote(str(x)) for x in cmd))\n",
    "    t0 = time.time()\n",
    "    proc = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    if proc.stdout: print(proc.stdout)\n",
    "    if proc.returncode != 0:\n",
    "        print(\"---- SNAP ERROR ----\")\n",
    "        if proc.stderr: print(proc.stderr)\n",
    "        raise subprocess.CalledProcessError(proc.returncode, cmd, output=proc.stdout, stderr=proc.stderr)\n",
    "    dt = time.time() - t0\n",
    "    print(f\"   ✓ wrote\\n     REF: {out_ref}\\n     BIO: {out_bio}\\n     SCL: {out_scl}  ({dt/60:.1f} min)\")\n",
    "    return out_ref, out_bio, out_scl\n",
    "\n",
    "\n",
    "# --- RUN ALL ---\n",
    "inputs = list_inputs_for_plot_tile()\n",
    "print(f\"Found {len(inputs)} S2 L2A inputs for {PLOT}/{TILE}\")\n",
    "for p in inputs:\n",
    "    print(f\"  - {p}   (date={acq_date_from_path(Path(p))})\")\n",
    "\n",
    "ok, fail = 0, 0\n",
    "for inp in inputs:\n",
    "    try:\n",
    "        run_one(Path(inp))\n",
    "        ok += 1\n",
    "    except Exception as e:\n",
    "        fail += 1\n",
    "        print(f\"   ✗ failed on {inp}\\n   {e}\")\n",
    "\n",
    "print(f\"\\nDone. Success: {ok}  Failures: {fail}\")\n",
    "print(f\"REF25: {len(list(REF_DIR.glob('*.dim')))}  BIO25: {len(list(BIO_DIR.glob('*.dim')))}  SCL25: {len(list(SCL_DIR.glob('*.dim')))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d8844c-4df0-4a41-8fec-697edb7348ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved to: A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_BIO_TC_Teruel_T30TXK.xml\n",
      "Inputs: 6 BIO products\n",
      "Intermediate DIM: A:\\S2\\work\\Teruel\\T30TXK\\BIO_TC\\Teruel_T30TXK_S2BIOTC.dim\n",
      "Deliverable BigTIFF: A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\\Teruel_20220000_S2BIOTC_T30TXK.tif\n",
      "Running: C:\\Program Files\\esa-snap\\bin\\gpt.exe A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_BIO_TC_Teruel_T30TXK.xml -c 8G\n",
      "\n",
      "[GPT stdout]\n",
      " Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "✓ BIO temporal composite complete in 7.6 min\n"
     ]
    }
   ],
   "source": [
    "# --- BIO temporal composite via SNAP GPT ---\n",
    "\n",
    "BIO25 = BIO_DIR                    # inputs: per-scene BIO .dim\n",
    "BIO_TC_DIR = WORK / \"BIO_TC\"        # intermediate composite .dim\n",
    "BIO_TC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Deliverables: final BigTIFF only\n",
    "DELIV_BIO = DELIV / \"BIO\"\n",
    "DELIV_BIO.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_DIM = BIO_TC_DIR / f\"{PLOT}_{TILE}_S2BIOTC.dim\"                          # intermediate\n",
    "OUT_TIF = DELIV_BIO / f\"{fmt_tag(REGION_TAG, YEAR, 'S2BIOTC', TILE)}.tif\"    # deliverable\n",
    "\n",
    "WRITE_TIF = True\n",
    "SKIP_IF_EXISTS = True\n",
    "\n",
    "bio_dims = sorted(BIO25.glob(\"*.dim\"))\n",
    "assert bio_dims, f\"No BIO .dim files found in {BIO25}\"\n",
    "if not Path(GPT_EXE).exists():\n",
    "    raise FileNotFoundError(f\"GPT not found at: {GPT_EXE}\")\n",
    "\n",
    "def list_bands_from_dim(dim_path: Path):\n",
    "    txt = dim_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    root = ET.fromstring(txt); names = []\n",
    "    for elem in root.iter():\n",
    "        tagu = elem.tag.upper()\n",
    "        if tagu.endswith(\"BAND_NAME\") and elem.text:\n",
    "            names.append(elem.text.strip())\n",
    "    if not names:\n",
    "        for elem in root.iter():\n",
    "            if elem.tag.upper().endswith(\"BAND\"):\n",
    "                nm = elem.attrib.get(\"name\")\n",
    "                if nm: names.append(nm.strip())\n",
    "    return names\n",
    "\n",
    "def detect_bio_bandnames(dim_path: Path):\n",
    "    names = [b.strip() for b in list_bands_from_dim(dim_path)]\n",
    "    lower = {n.lower(): n for n in names}\n",
    "    def pick(cands):\n",
    "        for c in cands:\n",
    "            if c.lower() in lower: return lower[c.lower()]\n",
    "        return None\n",
    "    mapping = {\n",
    "        \"LAI\":    pick([\"lai\",\"LAI\"]),\n",
    "        \"FAPAR\":  pick([\"fapar\",\"FAPAR\"]),\n",
    "        \"FCOVER\": pick([\"fcover\",\"Fcover\",\"FCOVER\",\"fvc\",\"FVC\"]),\n",
    "        \"Cab\":    pick([\"lai_cab\",\"cab\",\"Cab\",\"CAB\"]),\n",
    "        \"Cw\":     pick([\"lai_cw\",\"cw\",\"Cw\",\"CW\",\"cwc\",\"CWC\"]),\n",
    "    }\n",
    "    missing = [k for k,v in mapping.items() if v is None]\n",
    "    if missing:\n",
    "        short = names[:12] + ([\"...\"] if len(names) > 12 else [])\n",
    "        raise RuntimeError(f\"{dim_path.name}: missing bands {missing}. Found: {short}\")\n",
    "    return mapping\n",
    "\n",
    "def cdata(s: str) -> str: return f\"<![CDATA[{s}]]>\"\n",
    "\n",
    "def expr_avg(prefix: str, n_inputs: int) -> str:\n",
    "    names = [f\"{prefix}_{k}\" for k in range(1, n_inputs + 1)]\n",
    "    val   = [f\"(({nm}=={nm}) && ({nm}!={NODATA}))\" for nm in names]\n",
    "    num   = \" + \".join([f\"({v}?{nm}:0)\" for v,nm in zip(val,names)])\n",
    "    den   = \" + \".join([f\"({v}?1:0)\"     for v in val])\n",
    "    return f\"(({den})>0) ? (({num})/({den})) : NaN\"\n",
    "\n",
    "# ----- build XML -----\n",
    "read_nodes_xml, std_nodes_xml, merge_sources = [], [], []\n",
    "for i, p in enumerate(bio_dims, start=1):\n",
    "    rid, std = f\"Read{i}\", f\"Std{i}\"\n",
    "    m = detect_bio_bandnames(p)\n",
    "    read_nodes_xml.append(f\"\"\"\n",
    "  <node id=\"{rid}\">\n",
    "    <operator>Read</operator>\n",
    "    <parameters><file>{p}</file></parameters>\n",
    "  </node>\"\"\")\n",
    "    std_bands = \"\\n\".join([\n",
    "f\"\"\"      <targetBand><name>LAI_{i}</name><type>float32</type><expression>{cdata(m['LAI'])}</expression><noDataValue>NaN</noDataValue></targetBand>\"\"\",\n",
    "f\"\"\"      <targetBand><name>FAPAR_{i}</name><type>float32</type><expression>{cdata(m['FAPAR'])}</expression><noDataValue>NaN</noDataValue></targetBand>\"\"\",\n",
    "f\"\"\"      <targetBand><name>FCOVER_{i}</name><type>float32</type><expression>{cdata(m['FCOVER'])}</expression><noDataValue>NaN</noDataValue></targetBand>\"\"\",\n",
    "f\"\"\"      <targetBand><name>Cab_{i}</name><type>float32</type><expression>{cdata(m['Cab'])}</expression><noDataValue>NaN</noDataValue></targetBand>\"\"\",\n",
    "f\"\"\"      <targetBand><name>Cw_{i}</name><type>float32</type><expression>{cdata(m['Cw'])}</expression><noDataValue>NaN</noDataValue></targetBand>\"\"\"\n",
    "    ])\n",
    "    std_nodes_xml.append(f\"\"\"\n",
    "  <node id=\"{std}\">\n",
    "    <operator>BandMaths</operator>\n",
    "    <sources><sourceProduct refid=\"{rid}\"/></sources>\n",
    "    <parameters><targetBands>\n",
    "{std_bands}\n",
    "    </targetBands><variables/></parameters>\n",
    "  </node>\"\"\")\n",
    "    merge_sources.append(f'      <sourceProduct{\"\" if i==1 else f\".{i-1}\"} refid=\"{std}\"/>')\n",
    "\n",
    "bandmerge_xml = f\"\"\"\n",
    "  <node id=\"BandMerge\">\n",
    "    <operator>BandMerge</operator>\n",
    "    <sources>\n",
    "{chr(10).join(merge_sources)}\n",
    "    </sources>\n",
    "    <parameters><geographicError>1.0E-5</geographicError></parameters>\n",
    "  </node>\"\"\"\n",
    "\n",
    "tc_targets = []\n",
    "for prefix, outname in [(\"LAI\",\"LAI_TC\"), (\"FAPAR\",\"FAPAR_TC\"), (\"FCOVER\",\"FCOVER_TC\"), (\"Cab\",\"Cab_TC\"), (\"Cw\",\"Cw_TC\")]:\n",
    "    tc_targets.append(f\"\"\"\n",
    "      <targetBand>\n",
    "        <name>{outname}</name><type>float32</type>\n",
    "        <expression>{cdata(expr_avg(prefix, len(bio_dims)))}</expression>\n",
    "        <noDataValue>NaN</noDataValue>\n",
    "      </targetBand>\"\"\")\n",
    "\n",
    "bandmaths_tc_xml = f\"\"\"\n",
    "  <node id=\"BandMaths_TC\">\n",
    "    <operator>BandMaths</operator>\n",
    "    <sources><sourceProduct refid=\"BandMerge\"/></sources>\n",
    "    <parameters><targetBands>\n",
    "        {''.join(tc_targets)}\n",
    "    </targetBands><variables/></parameters>\n",
    "  </node>\"\"\"\n",
    "\n",
    "write_dim_xml = f\"\"\"\n",
    "  <node id=\"Write_DIM\">\n",
    "    <operator>Write</operator>\n",
    "    <sources><sourceProduct refid=\"BandMaths_TC\"/></sources>\n",
    "    <parameters>\n",
    "      <file>{OUT_DIM}</file>\n",
    "      <formatName>BEAM-DIMAP</formatName>\n",
    "    </parameters>\n",
    "  </node>\"\"\"\n",
    "\n",
    "write_tif_xml = f\"\"\"\n",
    "  <node id=\"Write_TIF\">\n",
    "    <operator>Write</operator>\n",
    "    <sources><sourceProduct refid=\"BandMaths_TC\"/></sources>\n",
    "    <parameters>\n",
    "      <file>{OUT_TIF}</file>\n",
    "      <formatName>GeoTIFF-BigTIFF</formatName>\n",
    "    </parameters>\n",
    "  </node>\"\"\" if WRITE_TIF else \"\"\n",
    "\n",
    "graph_xml = f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<graph id=\"BIO_TemporalComposite_{TILE}\">\n",
    "  <version>1.0</version>\n",
    "  {''.join(read_nodes_xml)}\n",
    "  {''.join(std_nodes_xml)}\n",
    "  {bandmerge_xml}\n",
    "  {bandmaths_tc_xml}\n",
    "  {write_dim_xml}\n",
    "  {write_tif_xml}\n",
    "</graph>\n",
    "\"\"\"\n",
    "\n",
    "# Save graph to global Graphs dir\n",
    "graphs_dir = WORK / \"_graphs\"\n",
    "graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "gpath = graphs_dir / f\"S2_BIO_TC_{PLOT}_{TILE}.xml\"\n",
    "gpath.write_text(graph_xml, encoding=\"utf-8\")\n",
    "print(\"Graph saved to:\", gpath)\n",
    "print(\"Inputs:\", len(bio_dims), \"BIO products\")\n",
    "print(\"Intermediate DIM:\", OUT_DIM)\n",
    "if WRITE_TIF: print(\"Deliverable BigTIFF:\", OUT_TIF)\n",
    "\n",
    "# Skip guard (don’t re-run if both outputs already exist)\n",
    "if SKIP_IF_EXISTS and OUT_DIM.exists() and (not WRITE_TIF or OUT_TIF.exists()):\n",
    "    print(\"• Skip BIO TC (exists)\")\n",
    "else:\n",
    "    cmd = [GPT_EXE, str(gpath), \"-c\", f\"{MEM_GB}G\"]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    t0 = time.time()\n",
    "    p = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if p.stdout.strip(): print(\"\\n[GPT stdout]\\n\", p.stdout)\n",
    "    if p.returncode != 0:\n",
    "        print(\"\\n[GPT stderr]\\n\", p.stderr)\n",
    "        raise RuntimeError(\"BIO temporal composite failed\")\n",
    "    print(f\"✓ BIO temporal composite complete in {(time.time()-t0)/60:.1f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27e3b20-9a72-4731-80ec-161317bf60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_CollocateOnly_Teruel_T30TXK.xml\n",
      ">> C:\\Program Files\\esa-snap\\bin\\gpt.exe A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_CollocateOnly_Teruel_T30TXK.xml\n",
      "Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "✓ Collocate-only → A:\\S2\\work\\Teruel\\T30TXK\\COLLOC\\Teruel_T30TXK_collocate_only.dim  (11.7 min)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A:\\\\S2\\\\work\\\\Teruel\\\\T30TXK\\\\COLLOC\\\\Teruel_T30TXK_collocate_only.dim'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collocation\n",
    "\n",
    "RE_ACQ = re.compile(r\"(\\d{8})T\\d{6}\")\n",
    "\n",
    "def _acq(p: Path) -> str:\n",
    "    m = RE_ACQ.search(p.name)\n",
    "    return m.group(1) if m else \"unknown\"\n",
    "\n",
    "def collect_tile_products(plot: str, tile: str):\n",
    "    ref_dir = WORK / \"REF25\"\n",
    "    scl_dir = WORK / \"SCL25\"\n",
    "    refs = list(ref_dir.glob(\"*.dim\"))\n",
    "    scls = list(scl_dir.glob(\"*.dim\"))\n",
    "    if not refs or not scls:\n",
    "        raise RuntimeError(f\"No REF/SCL found under {ref_dir} / {scl_dir}\")\n",
    "    ref_by_date = { _acq(p): p for p in refs }\n",
    "    scl_by_date = { _acq(p): p for p in scls }\n",
    "    dates = sorted(set(ref_by_date) & set(scl_by_date))\n",
    "    return [(d, ref_by_date[d], scl_by_date[d]) for d in dates]\n",
    "\n",
    "def write_collocate_stack_graph(plot: str, tile: str, pairs: list, out_dim: Path) -> Path:\n",
    "    \"\"\"\n",
    "    pairs = [(date, ref_path, scl_path), ...] in chronological order.\n",
    "    For each date: Merge(REF, SCL) so SCL travels with reflectance.\n",
    "    Then Collocate: master = Merge0, slaves = Merge1..MergeN-1.\n",
    "    \"\"\"\n",
    "    assert len(pairs) >= 2, \"Need at least 2 dates to collocate\"\n",
    "    if len(pairs) < 2:\n",
    "        raise RuntimeError(f\"Need >=2 dates to collocate, found {len(pairs)} for {PLOT}/{TILE}\")\n",
    "\n",
    "    reads_xml = []\n",
    "    merges_xml = []\n",
    "\n",
    "    # Build Read + Merge per date\n",
    "    for i, (d, refp, sclp) in enumerate(pairs):\n",
    "        reads_xml.append(f\"\"\"\n",
    "  <node id=\"Read_REF{i}\">\n",
    "    <operator>Read</operator>\n",
    "    <parameters>\n",
    "      <file>{refp}</file>\n",
    "    </parameters>\n",
    "  </node>\n",
    "  <node id=\"Read_SCL{i}\">\n",
    "    <operator>Read</operator>\n",
    "    <parameters>\n",
    "      <file>{sclp}</file>\n",
    "    </parameters>\n",
    "  </node>\"\"\")\n",
    "\n",
    "        # ✅ Merge has NO <parameters> block — just masterProduct + sourceProduct.n\n",
    "        merges_xml.append(f\"\"\"\n",
    "  <node id=\"Merge{i}\">\n",
    "    <operator>Merge</operator>\n",
    "    <sources>\n",
    "      <masterProduct>Read_REF{i}</masterProduct>\n",
    "      <sourceProduct.1>Read_SCL{i}</sourceProduct.1>\n",
    "    </sources>\n",
    "  </node>\"\"\")\n",
    "\n",
    "    # Collocate sources: master=Merge0, slaves=Merge1..MergeN-1\n",
    "    coll_src = [\"<master>Merge0</master>\"]\n",
    "    for i in range(1, len(pairs)):\n",
    "        coll_src.append(f\"<slave{i}>Merge{i}</slave{i}>\")\n",
    "    coll_src_xml = \"\\n      \".join(coll_src)\n",
    "\n",
    "    graph = f\"\"\"<graph id=\"S2_CollocateOnly_{plot}_{tile}\">\n",
    "  <version>1.0</version>\n",
    "  {''.join(reads_xml)}\n",
    "  {''.join(merges_xml)}\n",
    "  <node id=\"Collocate\">\n",
    "    <operator>Collocate</operator>\n",
    "    <sources>\n",
    "      {coll_src_xml}\n",
    "    </sources>\n",
    "    <parameters>\n",
    "      <copySecondaryMetadata>false</copySecondaryMetadata>\n",
    "      <renameReferenceComponents>true</renameReferenceComponents>\n",
    "      <renameSecondaryComponents>true</renameSecondaryComponents>\n",
    "      <referenceComponentPattern>${{ORIGINAL_NAME}}_M</referenceComponentPattern>\n",
    "      <secondaryComponentPattern>${{ORIGINAL_NAME}}_S${{SLAVE_NUMBER_ID}}</secondaryComponentPattern>\n",
    "      <resamplingType>BICUBIC_CONVOLUTION</resamplingType>\n",
    "    </parameters>\n",
    "  </node>\n",
    "  <node id=\"Write\">\n",
    "    <operator>Write</operator>\n",
    "    <sources>\n",
    "      <source>Collocate</source>\n",
    "    </sources>\n",
    "    <parameters>\n",
    "      <file>{out_dim}</file>\n",
    "    </parameters>\n",
    "  </node>\n",
    "</graph>\"\"\"\n",
    "\n",
    "    graphs_dir = WORK / \"_graphs\"\n",
    "    graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    gp = graphs_dir / f\"S2_CollocateOnly_{plot}_{tile}.xml\"\n",
    "    gp.write_text(graph, encoding=\"utf-8\")\n",
    "    return gp\n",
    "\n",
    "def run_collocate_stack(plot: str, tile: str, MEM_GB):\n",
    "    pairs = collect_tile_products(plot, tile)\n",
    "    colloc_dir = WORK / \"COLLOC\"\n",
    "    colloc_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_dim = colloc_dir / f\"{plot}_{tile}_collocate_only.dim\"\n",
    "    gp = write_collocate_stack_graph(plot, tile, pairs, out_dim)\n",
    "    print(\"Graph:\", gp)\n",
    "    print(\">>\", GPT_EXE, str(gp))\n",
    "    t0 = time.time()\n",
    "    p = subprocess.run([GPT_EXE, str(gp), \"-c\", f\"{MEM_GB}G\"], text=True, capture_output=True)\n",
    "    if p.stdout:\n",
    "        print(p.stdout)\n",
    "    if p.returncode != 0:\n",
    "        print(p.stderr)\n",
    "        raise RuntimeError(\"Collocate-only graph failed\")\n",
    "    print(f\"✓ Collocate-only → {out_dim}  ({(time.time()-t0)/60:.1f} min)\")\n",
    "    return str(out_dim)\n",
    "\n",
    "# Example run:\n",
    "colloc_dim = run_collocate_stack(PLOT, TILE, MEM_GB)\n",
    "colloc_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "082ba8c1-3c2f-4991-a837-1349ce423201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected suffixes: ['M', 'S0', 'S1', 'S2', 'S3', 'S4']\n",
      "Detected SCL base: quality_scene_classification\n",
      "Graph: A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_TC_from_collocated_Teruel_T30TXK.xml\n",
      ">> C:\\Program Files\\esa-snap\\bin\\gpt.exe A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_TC_from_collocated_Teruel_T30TXK.xml -c 8G\n",
      "Executing processing graph\n",
      "....10%....21%....32%....42%....53%....63%....73%....84%... done.\n",
      "\n",
      "✓ Temporal composite → A:\\S2\\work\\Teruel\\T30TXK\\COMPOSITE25\\Teruel_T30TXK_REF25_TC.dim  (3.3 min)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A:\\\\S2\\\\work\\\\Teruel\\\\T30TXK\\\\COMPOSITE25\\\\Teruel_T30TXK_REF25_TC.dim'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Temporal composite\n",
    "# --- CONFIG ---\n",
    "\n",
    "COLLOC_DIM = WORK / \"COLLOC\" / f\"{PLOT}_{TILE}_collocate_only.dim\"   # your collocate-only output\n",
    "OUT_DIR    = WORK / \"COMPOSITE25\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIM    = OUT_DIR / f\"{PLOT}_{TILE}_REF25_TC.dim\"\n",
    "\n",
    "SUFFIX_RE = re.compile(r\"_(M|S\\d+)$\")\n",
    "\n",
    "def list_bandnames_from_dim(dim_path: Path):\n",
    "    txt = dim_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    root = ET.fromstring(txt)\n",
    "    names = []\n",
    "    for elem in root.iter():\n",
    "        tagu = elem.tag.upper()\n",
    "        if tagu.endswith(\"BAND_NAME\") and elem.text:\n",
    "            names.append(elem.text.strip())\n",
    "    return names\n",
    "\n",
    "def detect_suffixes_and_scl_base(dim_path: Path):\n",
    "    \"\"\"\n",
    "    Returns (suffixes_list, scl_base).\n",
    "    - suffixes_list like [\"M\",\"S0\",\"S1\"] from what's actually present\n",
    "    - scl_base like \"quality_scene_classification\" detected from band names\n",
    "    \"\"\"\n",
    "    names = list_bandnames_from_dim(dim_path)\n",
    "    # 1) suffixes present\n",
    "    suffixes = sorted({SUFFIX_RE.search(n).group(1) for n in names if SUFFIX_RE.search(n)},\n",
    "                      key=lambda s: (s!=\"M\", int(s[1:]) if s.startswith(\"S\") else -1))\n",
    "    if not suffixes:\n",
    "        raise RuntimeError(\"Could not detect any collocate suffixes (_M, _S0, ...).\")\n",
    "\n",
    "    # 2) detect SCL base by looking for known prefixes + detected suffixes\n",
    "    scl_candidates = set()\n",
    "    for n in names:\n",
    "        m = SUFFIX_RE.search(n)\n",
    "        if not m:\n",
    "            continue\n",
    "        base = n[:m.start()]\n",
    "        low = base.lower()\n",
    "        if any(k in low for k in [\"scene_class\", \"quality\", \"scl\"]):\n",
    "            scl_candidates.add(base)\n",
    "\n",
    "    if not scl_candidates:\n",
    "        raise RuntimeError(\"Could not find an SCL band base name in the collocate product.\")\n",
    "\n",
    "    # Prefer the longest (most explicit) base\n",
    "    scl_base = sorted(scl_candidates, key=len, reverse=True)[0]\n",
    "    return suffixes, scl_base\n",
    "\n",
    "\n",
    "# Bands and masks\n",
    "SCL_BAD_VALUES = [0,1,3,7,8,9,10,11]\n",
    "SUFFIXES, SCL_BASE = detect_suffixes_and_scl_base(COLLOC_DIM)\n",
    "print(\"Detected suffixes:\", SUFFIXES)\n",
    "print(\"Detected SCL base:\", SCL_BASE)\n",
    "\n",
    "# SCL classes to EXCLUDE: 0=No data, 1=Saturated/defective, 3=Cloud shadows,\n",
    "# 7=Unclassified, 8=Cloud medium prob, 9=Cloud high prob, 10=Thin cirrus, 11=Snow/ice\n",
    "\n",
    "def _mask_expr(scl_name: str) -> str:\n",
    "    terms = [f\"({scl_name}!={v})\" for v in SCL_BAD_VALUES]\n",
    "    return \" && \".join(terms)\n",
    "\n",
    "def _band_mean_expr(band: str, suffixes: list[str]) -> str:\n",
    "    num_terms, den_terms = [], []\n",
    "    for suf in suffixes:\n",
    "        bname = f\"{band}_{suf}\"\n",
    "        scl   = f\"{SCL_BASE}_{suf}\"\n",
    "        valid = f\"({_mask_expr(scl)})\"\n",
    "        num_terms.append(f\"({bname} * ({valid} ? 1 : 0))\")\n",
    "        den_terms.append(f\"(({valid}) ? 1 : 0)\")\n",
    "    num = \" + \".join(num_terms)\n",
    "    den = \" + \".join(den_terms)\n",
    "    return f\"(({den}) > 0) ? ({num})/({den}) : NaN\"\n",
    "\n",
    "def write_tc_from_collocated(colloc_dim: Path, out_dim: Path) -> Path:\n",
    "    tgt_bands = []\n",
    "    for b in REF_BANDS:\n",
    "        expr = _band_mean_expr(b, SUFFIXES)\n",
    "        tgt_bands.append(\n",
    "            f\"\"\"\n",
    "            <targetBand>\n",
    "              <name>{b}_TC</name>\n",
    "              <type>float32</type>\n",
    "              <expression><![CDATA[{expr}]]></expression>\n",
    "              <noDataValue>NaN</noDataValue>\n",
    "            </targetBand>\"\"\"\n",
    "        )\n",
    "    graph = f\"\"\"<graph id=\"S2_TC_from_collocated_{PLOT}_{TILE}\">\n",
    "  <version>1.0</version>\n",
    "\n",
    "  <node id=\"Read\">\n",
    "    <operator>Read</operator>\n",
    "    <parameters>\n",
    "      <file>{colloc_dim}</file>\n",
    "    </parameters>\n",
    "  </node>\n",
    "\n",
    "  <node id=\"BandMaths_TC\">\n",
    "    <operator>BandMaths</operator>\n",
    "    <sources>\n",
    "      <sourceProduct refid=\"Read\"/>\n",
    "    </sources>\n",
    "    <parameters>\n",
    "      <targetBands>\n",
    "        {''.join(tgt_bands)}\n",
    "      </targetBands>\n",
    "    </parameters>\n",
    "  </node>\n",
    "\n",
    "  <node id=\"Write\">\n",
    "    <operator>Write</operator>\n",
    "    <sources>\n",
    "      <sourceProduct refid=\"BandMaths_TC\"/>\n",
    "    </sources>\n",
    "    <parameters>\n",
    "      <file>{out_dim}</file>\n",
    "    </parameters>\n",
    "  </node>\n",
    "</graph>\"\"\"\n",
    "    \n",
    "    graphs_dir = WORK / \"_graphs\"\n",
    "    graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    gp = graphs_dir / f\"S2_TC_from_collocated_{PLOT}_{TILE}.xml\"\n",
    "    gp.write_text(graph, encoding=\"utf-8\")\n",
    "    return gp\n",
    "\n",
    "def run_tc_from_collocated():\n",
    "    assert COLLOC_DIM.exists(), f\"Collocate-only product not found: {COLLOC_DIM}\"\n",
    "    gp = write_tc_from_collocated(COLLOC_DIM, OUT_DIM)\n",
    "    print(\"Graph:\", gp)\n",
    "    cmd = [GPT_EXE, str(gp), \"-c\", \"8G\"]\n",
    "    print(\">>\", \" \".join(map(str, cmd)))\n",
    "    t0 = time.time()\n",
    "    p = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    if p.stdout: print(p.stdout)\n",
    "    if p.returncode != 0:\n",
    "        print(p.stderr)\n",
    "        raise RuntimeError(\"Temporal composite (BandMaths-only) failed\")\n",
    "    print(f\"✓ Temporal composite → {OUT_DIM}  ({(time.time()-t0)/60:.1f} min)\")\n",
    "    return str(OUT_DIM)\n",
    "\n",
    "run_tc_from_collocated()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a64cf64c-58fd-4d73-a4fa-c1053c96c811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_GLCM_AllBands_Teruel_T30TXK.xml\n",
      ">> C:\\Program Files\\esa-snap\\bin\\gpt.exe A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_GLCM_AllBands_Teruel_T30TXK.xml -c 8G\n",
      "Executing processing graph\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "\n",
      "✓ GLCM (all bands) → A:\\S2\\work\\Teruel\\T30TXK\\GLCM25\\Teruel_T30TXK_GLCM_5x5_64gl_ALL_ALLBANDS.dim  (16.0 min)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A:\\\\S2\\\\work\\\\Teruel\\\\T30TXK\\\\GLCM25\\\\Teruel_T30TXK_GLCM_5x5_64gl_ALL_ALLBANDS.dim'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GLCM\n",
    "\n",
    "TC_DIM  = COMPOSITE_DIR / f\"{PLOT}_{TILE}_REF25_TC.dim\"\n",
    "\n",
    "OUT_DIR = GLCM_DIR\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIM = OUT_DIR / f\"{PLOT}_{TILE}_GLCM_5x5_64gl_ALL_ALLBANDS.dim\"\n",
    "\n",
    "WINDOW     = \"5x5\"\n",
    "ANGLES     = \"ALL\"\n",
    "QUANTIZER  = \"Probabilistic Quantizer\"\n",
    "GREYLEVELS = \"64\"\n",
    "DISP       = \"1\"\n",
    "NODATA     = \"-9999.0\"\n",
    "\n",
    "def write_glcm_allbands_graph(tc_dim: Path, out_dim: Path) -> Path:\n",
    "    # Read node\n",
    "    read_xml = f\"\"\"\n",
    "  <node id=\"ReadTC\">\n",
    "    <operator>Read</operator>\n",
    "    <parameters>\n",
    "      <file>{tc_dim}</file>\n",
    "    </parameters>\n",
    "  </node>\"\"\"\n",
    "\n",
    "    # One GLCM node per band\n",
    "    glcm_nodes = []\n",
    "    merge_sources = []\n",
    "    for i, band in enumerate(TC_BANDS, start=1):\n",
    "        node_id = f\"GLCM_{band}\"\n",
    "        glcm_nodes.append(f\"\"\"\n",
    "  <node id=\"{node_id}\">\n",
    "    <operator>GLCM</operator>\n",
    "    <sources>\n",
    "      <sourceProduct refid=\"ReadTC\"/>\n",
    "    </sources>\n",
    "    <parameters>\n",
    "      <sourceBands>{band}</sourceBands>\n",
    "      <windowSizeStr>{WINDOW}</windowSizeStr>\n",
    "      <angleStr>{ANGLES}</angleStr>\n",
    "      <quantizerStr>{QUANTIZER}</quantizerStr>\n",
    "      <quantizationLevelsStr>{GREYLEVELS}</quantizationLevelsStr>\n",
    "      <displacement>{DISP}</displacement>\n",
    "      <noDataValue>{NODATA}</noDataValue>\n",
    "\n",
    "      <outputContrast>true</outputContrast>\n",
    "      <outputDissimilarity>true</outputDissimilarity>\n",
    "      <outputHomogeneity>true</outputHomogeneity>\n",
    "      <outputASM>true</outputASM>\n",
    "      <outputEnergy>true</outputEnergy>\n",
    "      <outputMAX>true</outputMAX>\n",
    "      <outputEntropy>true</outputEntropy>\n",
    "      <outputMean>true</outputMean>\n",
    "      <outputVariance>true</outputVariance>\n",
    "      <outputCorrelation>true</outputCorrelation>\n",
    "    </parameters>\n",
    "  </node>\"\"\")\n",
    "        merge_sources.append(f'      <sourceProduct.{i} refid=\"{node_id}\"/>')\n",
    "\n",
    "    # Merge all GLCM outputs\n",
    "    merge_xml = f\"\"\"\n",
    "  <node id=\"BandMerge\">\n",
    "    <operator>BandMerge</operator>\n",
    "    <sources>\n",
    "{chr(10).join(merge_sources)}\n",
    "    </sources>\n",
    "    <parameters>\n",
    "      <geographicError>1.0E-5</geographicError>\n",
    "    </parameters>\n",
    "  </node>\"\"\"\n",
    "\n",
    "    # Write\n",
    "    write_xml = f\"\"\"\n",
    "  <node id=\"Write\">\n",
    "    <operator>Write</operator>\n",
    "    <sources>\n",
    "      <sourceProduct refid=\"BandMerge\"/>\n",
    "    </sources>\n",
    "    <parameters>\n",
    "      <file>{out_dim}</file>\n",
    "    </parameters>\n",
    "  </node>\"\"\"\n",
    "\n",
    "    graph = f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<graph id=\"S2_GLCM_AllBands_{PLOT}_{TILE}\">\n",
    "  <version>1.0</version>\n",
    "  {read_xml}\n",
    "  {''.join(glcm_nodes)}\n",
    "  {merge_xml}\n",
    "  {write_xml}\n",
    "</graph>\"\"\"\n",
    "    \n",
    "    graphs_dir = WORK / \"_graphs\"\n",
    "    graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    gp = graphs_dir / f\"S2_GLCM_AllBands_{PLOT}_{TILE}.xml\"\n",
    "    gp.write_text(graph, encoding=\"utf-8\")\n",
    "    return gp\n",
    "\n",
    "def run_glcm_allbands():\n",
    "    assert TC_DIM.exists(), f\"Missing TC: {TC_DIM}\"\n",
    "    gp = write_glcm_allbands_graph(TC_DIM, OUT_DIM)\n",
    "    print(\"Graph:\", gp)\n",
    "    cmd = [GPT_EXE, str(gp), \"-c\", \"8G\"]\n",
    "    print(\">>\", \" \".join(map(str, cmd)))\n",
    "    t0 = time.time()\n",
    "    p = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    if p.stdout: print(p.stdout)\n",
    "    if p.returncode != 0:\n",
    "        print(p.stderr)\n",
    "        # If SNAP parameter names differ, check:  \"gpt -h GLCM\"\n",
    "        raise RuntimeError(\"GLCM all-bands graph failed\")\n",
    "    print(f\"✓ GLCM (all bands) → {OUT_DIM}  ({(time.time()-t0)/60:.1f} min)\")\n",
    "    return str(OUT_DIM)\n",
    "\n",
    "run_glcm_allbands()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cd2350b-9a0d-4bd6-b1aa-0fc06f26d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: A:\\S2\\work\\Teruel\\T30TXK\\_graphs\\S2_ExportTC_Teruel_T30TXK.xml\n",
      "Executing processing graph\n",
      "....10%....21%....32%....42%....53%....63%....73%....84%... done.\n",
      "\n",
      "✓ Wrote A:\\S2\\Deliverables\\Teruel\\T30TXK\\S2TC\\Teruel_20220000_S2TC_T30TXK.tif  in 0.7 min\n",
      "Exists? True\n"
     ]
    }
   ],
   "source": [
    "# --- EXPORT STEP ---\n",
    "# Converts SNAP-native TC product (.dim) into GeoTIFF\n",
    "# for downstream Python / ML workflows (e.g. PCA, LightGBM).\n",
    "\n",
    "SRC_DIM   = COMPOSITE_DIR / f\"{PLOT}_{TILE}_REF25_TC.dim\"\n",
    "\n",
    "OUT_TIF   = Path(r\"A:\\S2\\Deliverables\") / REGION_TAG / TILE / \"S2TC\" / f\"{fmt_tag(REGION_TAG, YEAR, 'S2TC', TILE)}.tif\"\n",
    "OUT_TIF.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Skip guard\n",
    "if OUT_TIF.exists():\n",
    "    print(f\"• Skip export (exists): {OUT_TIF}\")\n",
    "else:\n",
    "    graph = f\"\"\"<graph id=\"Export_TC_TIFF\">\n",
    "  <version>1.0</version>\n",
    "  <node id=\"Read\">\n",
    "    <operator>Read</operator>\n",
    "    <parameters><file>{SRC_DIM}</file></parameters>\n",
    "  </node>\n",
    "  <node id=\"Subset\">\n",
    "    <operator>Subset</operator>\n",
    "    <sources><sourceProduct refid=\"Read\"/></sources>\n",
    "    <parameters>\n",
    "      <sourceBands>{','.join(TC_BANDS)}</sourceBands>\n",
    "      <copyMetadata>true</copyMetadata>\n",
    "    </parameters>\n",
    "  </node>\n",
    "  <node id=\"Write\">\n",
    "    <operator>Write</operator>\n",
    "    <sources><sourceProduct refid=\"Subset\"/></sources>\n",
    "    <parameters>\n",
    "      <file>{OUT_TIF}</file>\n",
    "      <formatName>GeoTIFF</formatName>\n",
    "      <!-- If needed for size: use GeoTIFF-BigTIFF -->\n",
    "    </parameters>\n",
    "  </node>\n",
    "</graph>\"\"\"\n",
    "\n",
    "    graphs_dir = WORK / \"_graphs\"\n",
    "    graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    gx = graphs_dir / f\"S2_ExportTC_{PLOT}_{TILE}.xml\"\n",
    "    gx.write_text(graph, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"Graph:\", gx)\n",
    "    t0 = time.time()\n",
    "    p = subprocess.run([GPT_EXE, str(gx), \"-c\", \"8G\"], text=True, capture_output=True)\n",
    "    print(p.stdout)\n",
    "    if p.returncode != 0:\n",
    "        print(p.stderr)\n",
    "        raise RuntimeError(\"Export to GeoTIFF failed\")\n",
    "    print(f\"✓ Wrote {OUT_TIF}  in {(time.time()-t0)/60:.1f} min\")\n",
    "    print(\"Exists?\", OUT_TIF.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "283bbc7d-357d-4c53-9fa5-3264468fef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Plan ==\n",
      "TC dim : A:\\S2\\work\\Teruel\\T30TXK\\COMPOSITE25\\Teruel_T30TXK_REF25_TC.dim\n",
      "TC tif : A:\\S2\\Deliverables\\Teruel\\T30TXK\\S2TC\\Teruel_20220000_S2TC_T30TXK.tif\n",
      "BIO dims: 6\n",
      "GLCM dim: A:\\S2\\work\\Teruel\\T30TXK\\GLCM25\\Teruel_T30TXK_GLCM_5x5_64gl_ALL_ALLBANDS.dim\n",
      "GLCM tif: A:\\S2\\Deliverables\\Teruel\\T30TXK\\GLCM\\Teruel_20220000_GLCM_T30TXK.tif\n",
      "\n",
      "• Skip (exists) A:\\S2\\Deliverables\\Teruel\\T30TXK\\S2TC\\Teruel_20220000_S2TC_T30TXK.tif\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_BIO25.read2tif.xml' -c 8G\n",
      "Executing processing graph\n",
      "....10%....21%....32%....43%....54%....65%....75%....86%.. done.\n",
      "\n",
      "✓ Wrote via S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_BIO25.read2tif.xml in 0.4 min\n",
      "→ A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\\S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_BIO25.tif\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_BIO25.read2tif.xml' -c 8G\n",
      "Executing processing graph\n",
      "....10%....21%....32%....43%....54%....65%....75%....86%.. done.\n",
      "\n",
      "✓ Wrote via S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_BIO25.read2tif.xml in 0.4 min\n",
      "→ A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\\S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_BIO25.tif\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_BIO25.read2tif.xml' -c 8G\n",
      "Executing processing graph\n",
      "....10%....21%....32%....43%....54%....65%....75%....86%.. done.\n",
      "\n",
      "✓ Wrote via S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_BIO25.read2tif.xml in 0.4 min\n",
      "→ A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\\S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_BIO25.tif\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_BIO25.read2tif.xml' -c 8G\n",
      "Executing processing graph\n",
      "....10%....21%....32%....43%....54%....65%....75%....86%.. done.\n",
      "\n",
      "✓ Wrote via S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_BIO25.read2tif.xml in 0.4 min\n",
      "→ A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\\S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_BIO25.tif\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_BIO25.read2tif.xml' -c 8G\n",
      "Executing processing graph\n",
      "....10%....21%....32%....43%....54%....65%....75%....86%.. done.\n",
      "\n",
      "✓ Wrote via S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_BIO25.read2tif.xml in 0.4 min\n",
      "→ A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\\S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_BIO25.tif\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\BIO25\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_BIO25.read2tif.xml' -c 8G\n",
      "Executing processing graph\n",
      "....10%....21%....32%....43%....54%....65%....75%....86%.. done.\n",
      "\n",
      "✓ Wrote via S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_BIO25.read2tif.xml in 0.4 min\n",
      "→ A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\\S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_BIO25.tif\n",
      ">> 'C:\\Program Files\\esa-snap\\bin\\gpt.exe' 'A:\\S2\\work\\Teruel\\T30TXK\\GLCM25\\Teruel_T30TXK_GLCM_5x5_64gl_ALL_ALLBANDS.read2tif.xml' -c 8G\n",
      "Executing processing graph\n",
      "....10%....21%....32%....43%....54%....65%....75%....86%.. done.\n",
      "\n",
      "✓ Wrote via Teruel_T30TXK_GLCM_5x5_64gl_ALL_ALLBANDS.read2tif.xml in 20.4 min\n",
      "→ A:\\S2\\Deliverables\\Teruel\\T30TXK\\GLCM\\Teruel_20220000_GLCM_T30TXK.tif\n",
      "✓ Wrote A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\README_bandmap.txt\n",
      "\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "# === EXPORT & DOCUMENTATION (GeoTIFF + README, dim-first) ===\n",
    "\n",
    "SKIP_IF_EXISTS = True\n",
    "\n",
    "# ---------- STATIC BAND MAPS (fallbacks only) ----------\n",
    "BAND_MAPS = {\n",
    "    # S2 temporal composite (12 bands)\n",
    "    \"S2TC\": [\n",
    "        \"B1 (Aerosol, 443 nm)\",\n",
    "        \"B2 (Blue, 490 nm)\",\n",
    "        \"B3 (Green, 560 nm)\",\n",
    "        \"B4 (Red, 665 nm)\",\n",
    "        \"B5 (705 nm)\",\n",
    "        \"B6 (740 nm)\",\n",
    "        \"B7 (783 nm)\",\n",
    "        \"B8 (NIR, 842 nm)\",\n",
    "        \"B8A (865 nm)\",\n",
    "        \"B9 (940 nm)\",\n",
    "        \"B11 (SWIR 1610 nm)\",\n",
    "        \"B12 (SWIR 2190 nm)\",\n",
    "    ],\n",
    "    # BIO temporal composite (5): *_TC bands\n",
    "    \"BIO\": [\"LAI_TC\",\"FAPAR_TC\",\"FCOVER_TC\",\"Cab_TC\",\"Cw_TC\"],\n",
    "    # BIO per-date (10): value + flags for each variable, order matches your SNAP chain\n",
    "    \"BIO10\": [\n",
    "        \"LAI\",\"LAI_flags\",\n",
    "        \"Cab\",\"Cab_flags\",\n",
    "        \"Cw\",\"Cw_flags\",\n",
    "        \"FAPAR\",\"FAPAR_flags\",\n",
    "        \"FCOVER\",\"FCOVER_flags\",\n",
    "    ],\n",
    "    # SCL (kept here if you ever export SCL to GeoTIFF)\n",
    "    \"SCL\": [\n",
    "        \"0 = No data\",\"1 = Saturated/defective\",\"2 = Dark area pixels\",\n",
    "        \"3 = Cloud shadows\",\"4 = Vegetation\",\"5 = Bare soils\",\"6 = Water\",\n",
    "        \"7 = Clouds low probability\",\"8 = Clouds medium probability\",\n",
    "        \"9 = Clouds high probability\",\"10 = Cirrus\",\"11 = Snow / ice\",\n",
    "    ],\n",
    "    # GLCM name synthesis (stat list)\n",
    "    \"GLCM_STATS\": [\n",
    "        \"Contrast\",\"Dissimilarity\",\"Homogeneity\",\"ASM\",\"Energy\",\n",
    "        \"MAX\",\"Entropy\",\"GLCMMean\",\"GLCMVariance\",\"GLCMCorrelation\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# ---------- SNAP helpers ----------\n",
    "def write_graph_read_to_geotiff(src_dim: Path, dst_tif: Path, bigtiff=False) -> Path:\n",
    "    \"\"\"Tiny SNAP graph: Read -> Write(GeoTIFF/BigTIFF). Returns .xml path.\"\"\"\n",
    "    fmt = \"GeoTIFF-BigTIFF\" if bigtiff else \"GeoTIFF\"\n",
    "    graph = f\"\"\"<graph id=\"ReadToGTiff\">\n",
    "  <version>1.0</version>\n",
    "  <node id=\"Read\">\n",
    "    <operator>Read</operator>\n",
    "    <parameters><file>{src_dim}</file></parameters>\n",
    "  </node>\n",
    "  <node id=\"Write\">\n",
    "    <operator>Write</operator>\n",
    "    <sources><sourceProduct refid=\"Read\"/></sources>\n",
    "    <parameters>\n",
    "      <file>{dst_tif}</file>\n",
    "      <formatName>{fmt}</formatName>\n",
    "    </parameters>\n",
    "  </node>\n",
    "</graph>\"\"\"\n",
    "    gp = src_dim.with_suffix(\".read2tif.xml\")\n",
    "    gp.write_text(graph, encoding=\"utf-8\")\n",
    "    return gp\n",
    "\n",
    "def run_gpt(graph_path: Path, MEM_GB):\n",
    "    cmd = [GPT_EXE, str(graph_path), \"-c\", f\"{MEM_GB}G\"]\n",
    "    print(\">>\", \" \".join(shlex.quote(str(x)) for x in cmd))\n",
    "    t0 = time.time()\n",
    "    p = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    if p.stdout: print(p.stdout)\n",
    "    if p.returncode != 0:\n",
    "        print(p.stderr)\n",
    "        raise RuntimeError(f\"GPT failed on {graph_path.name}\")\n",
    "    print(f\"✓ Wrote via {graph_path.name} in {(time.time()-t0)/60:.1f} min\")\n",
    "\n",
    "# ---------- .dim band-name extractor (robust, simple) ----------\n",
    "def extract_band_names_from_dim(dim_path: Path) -> list[str]:\n",
    "    \"\"\"Return band names in order from SNAP .dim; empty list if not found/parsable.\"\"\"\n",
    "    if not dim_path or not dim_path.exists():\n",
    "        return []\n",
    "    try:\n",
    "        root = ET.parse(dim_path).getroot()\n",
    "    except Exception:\n",
    "        return []\n",
    "    # 1) <BandList>/<Band>/<Name>\n",
    "    names = [b.findtext(\"Name\") for b in root.findall(\".//BandList/Band\")]\n",
    "    names = [n for n in names if n]\n",
    "    if names: return names\n",
    "    # 2) Fallbacks\n",
    "    alt = []\n",
    "    for b in root.findall(\".//Band\"):\n",
    "        nm = b.get(\"name\") or b.findtext(\"Name\") or b.findtext(\"name\")\n",
    "        if nm: alt.append(nm)\n",
    "    if alt: return alt\n",
    "    alt = []\n",
    "    for rdn in root.findall(\".//RasterDataNode\"):\n",
    "        nm = rdn.findtext(\"name\")\n",
    "        if nm: alt.append(nm)\n",
    "    if alt: return alt\n",
    "    alt = []\n",
    "    for sbi in root.findall(\".//Spectral_Band_Info\"):\n",
    "        nm = sbi.get(\"name\") or sbi.findtext(\"name\")\n",
    "        if nm: alt.append(nm)\n",
    "    return alt\n",
    "\n",
    "# ---------- Minimal README writer (no TIFF reads) ----------\n",
    "def generate_readme_simple(\n",
    "    plot:str, tile:str, year:str,\n",
    "    work_tile_dir:Path, deliver_tile_dir:Path,\n",
    "    region_tag:str=None, crs_hint:str=None, pixel_size_m:int=25,\n",
    "    include_fallback_notes:bool=True\n",
    ") -> Path:\n",
    "    \"\"\"Writes README_bandmap.txt in deliver_tile_dir using .dim if present, otherwise BAND_MAPS fallbacks.\"\"\"\n",
    "    region_tag = region_tag or plot\n",
    "    if crs_hint is None:\n",
    "        crs_hint = \"EPSG:3763 (Portugal)\" if \"Serra\" in region_tag else \"EPSG:25830 (Spain)\"\n",
    "\n",
    "    # Work (for .dim discovery)\n",
    "    COMPOSITE_DIR = work_tile_dir / \"COMPOSITE25\"\n",
    "    BIO_DIR       = work_tile_dir / \"BIO25\"\n",
    "    GLCM_DIR      = work_tile_dir / \"GLCM25\"\n",
    "\n",
    "    tc_dim   = next(COMPOSITE_DIR.glob(\"*_REF25_TC.dim\"), None) if COMPOSITE_DIR.exists() else None\n",
    "    bio_dims = sorted(BIO_DIR.glob(\"*.dim\")) if BIO_DIR.exists() else []\n",
    "    glcm_dim = next(GLCM_DIR.glob(\"*.dim\"), None) if GLCM_DIR.exists() else None\n",
    "\n",
    "    # Deliverables (decide which sections to document)\n",
    "    D_S2TC = deliver_tile_dir / \"S2TC\"\n",
    "    D_BIO  = deliver_tile_dir / \"BIO\"\n",
    "    D_GLCM = deliver_tile_dir / \"GLCM\"\n",
    "\n",
    "    tc_tif   = next(D_S2TC.glob(f\"{region_tag}_{year}0000_S2TC_{tile}.tif\"), None) if D_S2TC.exists() else None\n",
    "    bio_tifs = sorted(D_BIO.glob(\"*.tif\")) if D_BIO.exists() else []\n",
    "    glcm_tif = next(D_GLCM.glob(f\"{region_tag}_{year}0000_GLCM_{tile}.tif\"), None) if D_GLCM.exists() else None\n",
    "\n",
    "    def write_section(lines, label, names, filelabel, fallback_key=None):\n",
    "        if include_fallback_notes and fallback_key:\n",
    "            lines.append(f\"(Used fallback band list for {fallback_key})\")\n",
    "        lines.append(\"-\"*64)\n",
    "        lines.append(label)\n",
    "        lines.append(f\"File: {filelabel}\")\n",
    "        lines.append(f\"Bands ({len(names)}):\")\n",
    "        for i, nm in enumerate(names, 1):\n",
    "            lines.append(f\"  band_{i} = {nm}\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    dataset_dir = deliver_tile_dir / \"DATASET\"\n",
    "    dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_txt = dataset_dir / \"README_bandmap.txt\"\n",
    "    lines = [\n",
    "        \"README_bandmap.txt\",\"------------------\\n\",\n",
    "        f\"Region: {region_tag}\", f\"Tile: {tile}\", f\"Year: {year}\",\n",
    "        f\"Projection: {crs_hint}\", f\"Resolution: {pixel_size_m} m\",\"\",\n",
    "        \"Notes:\",\n",
    "        \"- Band names come from .dim when available; otherwise a standard list is used.\",\n",
    "        \"- GeoTIFF band order mirrors the source .dim order; TIFF metadata was not read.\",\n",
    "        \"- *_CLIP.tif keep the same band order as their originals.\",\"\"\n",
    "    ]\n",
    "\n",
    "    # S2TC\n",
    "    if tc_tif:\n",
    "        names = extract_band_names_from_dim(tc_dim) if tc_dim else []\n",
    "        write_section(lines, \"S2TC (Reflectance temporal composite)\",\n",
    "                      names if names else BAND_MAPS[\"S2TC\"], tc_tif.name,\n",
    "                      None if names else \"S2TC\")\n",
    "\n",
    "    # BIO (split composite vs per-date by filename)\n",
    "    if bio_tifs:\n",
    "        bio_tc = [t for t in bio_tifs if re.search(r\"S2BIOTC|_BIO25_TC\", t.name, re.I)]\n",
    "        bio_dt = [t for t in bio_tifs if t not in bio_tc]\n",
    "\n",
    "        for t in bio_tc:\n",
    "            dim = next((d for d in bio_dims if d.stem == t.stem[:-4]), None)\n",
    "            names = extract_band_names_from_dim(dim) if dim else []\n",
    "            write_section(lines, \"BIO (Biophysical temporal composite)\",\n",
    "                          names if names else BAND_MAPS[\"BIO\"], t.name,\n",
    "                          None if names else \"BIO\")\n",
    "\n",
    "        for t in bio_dt:\n",
    "            dim = next((d for d in bio_dims if d.stem == t.stem[:-4]), None)\n",
    "            names = extract_band_names_from_dim(dim) if dim else []\n",
    "            write_section(lines, \"BIO (Per-date biophysical product)\",\n",
    "                          names if names else BAND_MAPS[\"BIO10\"], t.name,\n",
    "                          None if names else \"per-date BIO\")\n",
    "\n",
    "    # GLCM\n",
    "    if glcm_tif:\n",
    "        names = extract_band_names_from_dim(glcm_dim) if glcm_dim else []\n",
    "        if not names:\n",
    "            # synthesize 12 S2TC bands × 10 stats = 120\n",
    "            base = [b.split()[0] for b in BAND_MAPS[\"S2TC\"]]  # \"B1 (Aerosol...\" -> \"B1\"\n",
    "            stats = BAND_MAPS[\"GLCM_STATS\"]\n",
    "            names = [f\"{b}_{s}\" for b in base for s in stats]\n",
    "            write_section(lines, \"GLCM (Texture features from REF_TC)\", names, glcm_tif.name, \"GLCM\")\n",
    "        else:\n",
    "            write_section(lines, \"GLCM (Texture features from REF_TC)\", names, glcm_tif.name)\n",
    "\n",
    "    out_txt.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    print(f\"✓ Wrote {out_txt}\")\n",
    "    return out_txt\n",
    "\n",
    "# ---------- Locate inputs/outputs ----------\n",
    "ROOT = WORK\n",
    "COMPOSITE_DIR = ROOT / \"COMPOSITE25\"\n",
    "BIO_DIR       = ROOT / \"BIO25\"\n",
    "GLCM_DIR      = ROOT / \"GLCM25\"\n",
    "\n",
    "# Deliverables\n",
    "D_TILE   = DELIV \n",
    "D_S2TC   = D_TILE / \"S2TC\"\n",
    "D_BIO    = D_TILE / \"BIO\"\n",
    "D_GLCM   = D_TILE / \"GLCM\"\n",
    "for d in (D_S2TC, D_BIO, D_GLCM):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Expected products\n",
    "tc_src = next(COMPOSITE_DIR.glob(\"*_REF25_TC.dim\"), None)\n",
    "tc_tif = D_S2TC / f\"{fmt_tag(REGION_TAG, YEAR, 'S2TC', TILE)}.tif\"\n",
    "\n",
    "bio_dims = sorted(BIO_DIR.glob(\"*.dim\"))\n",
    "bio_outs = [D_BIO / (p.stem + \".tif\") for p in bio_dims]\n",
    "\n",
    "glcm_src = next(GLCM_DIR.glob(\"*.dim\"), None)\n",
    "glcm_tif = D_GLCM / f\"{fmt_tag(REGION_TAG, YEAR, 'GLCM', TILE)}.tif\" if glcm_src else None\n",
    "\n",
    "print(\"== Plan ==\")\n",
    "print(\"TC dim :\", tc_src)\n",
    "print(\"TC tif :\", tc_tif)\n",
    "print(\"BIO dims:\", len(bio_dims))\n",
    "print(\"GLCM dim:\", glcm_src)\n",
    "print(\"GLCM tif:\", glcm_tif)\n",
    "print()\n",
    "\n",
    "# ---------- Convert (resilient to missing .dim) ----------\n",
    "# 1) S2TC\n",
    "if tc_src is None:\n",
    "    if tc_tif.exists():\n",
    "        print(f\"• No TC .dim, but TIF exists → skipping export: {tc_tif}\")\n",
    "    else:\n",
    "        print(f\"• WARN: No TC .dim and no TIF → skipping S2TC for {PLOT}/{TILE}\")\n",
    "else:\n",
    "    if tc_tif.exists() and SKIP_IF_EXISTS:\n",
    "        print(f\"• Skip (exists) {tc_tif}\")\n",
    "    else:\n",
    "        gp = write_graph_read_to_geotiff(tc_src, tc_tif, bigtiff=False)\n",
    "        run_gpt(gp, MEM_GB)\n",
    "        print(f\"→ {tc_tif}\")\n",
    "\n",
    "# 2) BIO per-date\n",
    "if bio_dims:\n",
    "    for src_dim, dst_tif in zip(bio_dims, bio_outs):\n",
    "        if dst_tif.exists() and SKIP_IF_EXISTS:\n",
    "            print(f\"• Skip (exists) {dst_tif}\")\n",
    "            continue\n",
    "        gp = write_graph_read_to_geotiff(src_dim, dst_tif, bigtiff=False)\n",
    "        run_gpt(gp, MEM_GB)\n",
    "        print(f\"→ {dst_tif}\")\n",
    "else:\n",
    "    print(\"• No per-date BIO .dim files found — assuming BIO TIFs already exported or not needed.\")\n",
    "\n",
    "# 3) GLCM\n",
    "if glcm_src is None:\n",
    "    if glcm_tif and glcm_tif.exists():\n",
    "        print(f\"• No GLCM .dim, but TIF exists → skipping export: {glcm_tif}\")\n",
    "    else:\n",
    "        print(f\"• WARN: No GLCM .dim and no TIF → skipping GLCM for {PLOT}/{TILE}\")\n",
    "else:\n",
    "    if glcm_tif.exists() and SKIP_IF_EXISTS:\n",
    "        print(f\"• Skip (exists) {glcm_tif}\")\n",
    "    else:\n",
    "        gp = write_graph_read_to_geotiff(glcm_src, glcm_tif, bigtiff=True)\n",
    "        run_gpt(gp, MEM_GB)\n",
    "        print(f\"→ {glcm_tif}\")\n",
    "\n",
    "# ---------- README: always generate next to deliverables ----------\n",
    "_ = generate_readme_simple(\n",
    "    plot=PLOT, tile=TILE, year=YEAR,\n",
    "    work_tile_dir=ROOT,\n",
    "    deliver_tile_dir=D_TILE,\n",
    "    region_tag=REGION_TAG\n",
    ")\n",
    "\n",
    "print(\"\\nAll done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fe81187-b8ba-4952-8631-57a39d2e7972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\QA\\Teruel_20220000_SCL_TALLY_T30TXK.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- CONFIG: locate SCL and where to write QA ---\n",
    "WORK_ROOT = Path(r\"A:\\S2\\work\")\n",
    "SCL_DIR   = WORK_ROOT / PLOT / TILE / \"SCL25\"\n",
    "\n",
    "QA_DIR = Path(r\"A:\\S2\\Deliverables\") / REGION_TAG / TILE / \"DATASET\" / \"QA\"\n",
    "QA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_CSV = QA_DIR / f\"{fmt_tag(REGION_TAG, YEAR, 'SCL_TALLY', TILE)}.csv\"\n",
    "\n",
    "# Sentinel-2 SCL legend (0..11)\n",
    "SCL_MAP = {\n",
    "    0:\"No data\", 1:\"Saturated/defective\", 2:\"Dark features/shadows\", 3:\"Cloud shadows\",\n",
    "    4:\"Vegetation\", 5:\"Bare soils\", 6:\"Water\", 7:\"Unclassified\",\n",
    "    8:\"Cloud medium prob.\", 9:\"Cloud high prob.\", 10:\"Thin cirrus\", 11:\"Snow/ice\",\n",
    "}\n",
    "BAD_CLOUD = {3,8,9,10,11}        # clouds-only fraction\n",
    "BAD_ALL   = {0,1,3,7,8,9,10,11}  # your masking set (keeps 2,4,5,6)\n",
    "\n",
    "def resolve_scl_raster(dim_path: Path) -> Path:\n",
    "    \"\"\"Given an SCL .dim, return the path to its .img band.\"\"\"\n",
    "    if dim_path.suffix.lower() != \".dim\":\n",
    "        return dim_path  # already a raster (e.g., .tif/.img)\n",
    "    data_dir = dim_path.with_suffix(\".data\")\n",
    "    # Typical SNAP band name for SCL:\n",
    "    cands = list(data_dir.glob(\"quality_scene_classification*.img\"))\n",
    "    if not cands:\n",
    "        cands = list(data_dir.glob(\"*SCL*.img\")) + list(data_dir.glob(\"*.img\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"No .img band files under {data_dir}\")\n",
    "    return cands[0]\n",
    "\n",
    "def scl_histogram(raster_path: Path):\n",
    "    counts = {k: 0 for k in SCL_MAP}\n",
    "    total = 0\n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        for _, window in ds.block_windows(1):\n",
    "            arr = ds.read(1, window=window, masked=True)\n",
    "            data = arr.compressed().astype(np.int32)\n",
    "            total += data.size\n",
    "            if data.size:\n",
    "                bc = np.bincount(data, minlength=12)\n",
    "                for k in range(min(12, len(bc))):\n",
    "                    counts[k] += int(bc[k])\n",
    "    return counts, total\n",
    "\n",
    "def write_folder_tally(scl_dir: Path, out_csv: Path):\n",
    "    dims = sorted(scl_dir.glob(\"*.dim\"))\n",
    "    if not dims:\n",
    "        raise FileNotFoundError(f\"No .dim files in {scl_dir}\")\n",
    "\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    grand_counts = {k: 0 for k in SCL_MAP}\n",
    "    grand_total = 0\n",
    "\n",
    "    with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"scene\", \"class\", \"label\", \"count\", \"fraction\", \"percent\",\n",
    "                    \"cloud_frac\", \"mask_all_frac\", \"dark_frac\"])\n",
    "\n",
    "        for dim in dims:\n",
    "            scene = dim.stem\n",
    "            img = resolve_scl_raster(dim)\n",
    "            counts, total = scl_histogram(img)\n",
    "            cloud = sum(counts[k] for k in BAD_CLOUD)\n",
    "            mask_all = sum(counts[k] for k in BAD_ALL)\n",
    "            dark = counts.get(2, 0)\n",
    "\n",
    "            # per-class rows for this scene\n",
    "            for k in range(12):\n",
    "                n = counts.get(k, 0)\n",
    "                frac = (n/total) if total else 0.0\n",
    "                w.writerow([scene, k, SCL_MAP[k], n, f\"{frac:.6f}\", f\"{100*frac:.2f}\",\n",
    "                            f\"{(cloud/total) if total else 0:.6f}\",\n",
    "                            f\"{(mask_all/total) if total else 0:.6f}\",\n",
    "                            f\"{(dark/total) if total else 0:.6f}\"])\n",
    "\n",
    "            # accumulate for grand summary\n",
    "            for k in grand_counts:\n",
    "                grand_counts[k] += counts.get(k, 0)\n",
    "            grand_total += total\n",
    "\n",
    "        # aggregated summary\n",
    "        w.writerow([])\n",
    "        w.writerow([\"ALL_SCENES\", \"—\", \"—\", \"—\", \"—\", \"—\", \"—\", \"—\", \"—\"])\n",
    "        cloud = sum(grand_counts[k] for k in BAD_CLOUD)\n",
    "        mask_all = sum(grand_counts[k] for k in BAD_ALL)\n",
    "        dark = grand_counts.get(2, 0)\n",
    "        for k in range(12):\n",
    "            n = grand_counts.get(k, 0)\n",
    "            frac = (n/grand_total) if grand_total else 0.0\n",
    "            w.writerow([\"ALL_SCENES\", k, SCL_MAP[k], n, f\"{frac:.6f}\", f\"{100*frac:.2f}\",\n",
    "                        f\"{(cloud/grand_total) if grand_total else 0:.6f}\",\n",
    "                        f\"{(mask_all/grand_total) if grand_total else 0:.6f}\",\n",
    "                        f\"{(dark/grand_total) if grand_total else 0:.6f}\"])\n",
    "\n",
    "    return out_csv\n",
    "\n",
    "# Run it (optional skip guard)\n",
    "if OUT_CSV.exists():\n",
    "    print(f\"• Skip QA (exists): {OUT_CSV}\")\n",
    "else:\n",
    "    print(\"→\", write_folder_tally(SCL_DIR, OUT_CSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76cf4f24-370a-49cf-a4e7-faf0ba678e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== S2 Data Builder ==\n",
      "• S2TC: ['Teruel_20220000_S2TC_T30TXK.tif']\n",
      "• BIO_TC: ['Teruel_20220000_S2BIOTC_T30TXK.tif']\n",
      "• BIO per-date: 6\n",
      "• GLCM: ['Teruel_20220000_GLCM_T30TXK.tif']\n",
      "[S2TC] Teruel_20220000_S2TC_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B01_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B02_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B03_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B04_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B05_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B06_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B07_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B08_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B8A_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B09_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B11_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_B12_T30TXK.tif\n",
      "[BIO] Teruel_20220000_S2BIOTC_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_T30TXK.tif\n",
      "[BIO] S2A_MSIL2A_20220619T104631_N0510_R051_T30TXK_20240628T024845_20220619_T30TXK_BIO25.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_FLAGS_T30TXK.tif\n",
      "[BIO] S2A_MSIL2A_20220828T104631_N0510_R051_T30TXK_20240708T151011_20220828_T30TXK_BIO25.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_FLAGS_T30TXK.tif\n",
      "[BIO] S2A_MSIL2A_20220927T104821_N0510_R051_T30TXK_20240726T195157_20220927_T30TXK_BIO25.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_FLAGS_T30TXK.tif\n",
      "[BIO] S2B_MSIL2A_20220515T104619_N0510_R051_T30TXK_20240620T040133_20220515_T30TXK_BIO25.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_FLAGS_T30TXK.tif\n",
      "[BIO] S2B_MSIL2A_20220724T104629_N0510_R051_T30TXK_20240710T190140_20220724_T30TXK_BIO25.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_FLAGS_T30TXK.tif\n",
      "[BIO] S2B_MSIL2A_20221002T104759_N0510_R051_T30TXK_20240724T091405_20221002_T30TXK_BIO25.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_LAI_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CAB_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_CWC_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FAPAR_FLAGS_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_T30TXK.tif\n",
      "• Skip (exists): Teruel_20220000_S2_FCOVER_FLAGS_T30TXK.tif\n",
      "[GLCM] Teruel_20220000_GLCM_T30TXK.tif\n",
      ">> gdal_translate -b 1 -a_nodata -9999.0 -of GTiff A:\\S2\\Deliverables\\Teruel\\T30TXK\\GLCM\\Teruel_20220000_GLCM_T30TXK.tif A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01CONTRAST_T30TXK.tmp.tif\n",
      "Input file size is 4392, 4392\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      ">> gdalwarp -overwrite -t_srs EPSG:25830 -srcnodata -9999.0 -dstnodata -9999.0 -r bilinear -multi A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01CONTRAST_T30TXK.tmp.tif A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01CONTRAST_T30TXK.tif\n",
      "Creating output file that is 4392P x 4392L.\n",
      "Processing A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01CONTRAST_T30TXK.tmp.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      ">> gdal_translate -b 2 -a_nodata -9999.0 -of GTiff A:\\S2\\Deliverables\\Teruel\\T30TXK\\GLCM\\Teruel_20220000_GLCM_T30TXK.tif A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01DISSIMILARITY_T30TXK.tmp.tif\n",
      "Input file size is 4392, 4392\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      ">> gdalwarp -overwrite -t_srs EPSG:25830 -srcnodata -9999.0 -dstnodata -9999.0 -r bilinear -multi A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01DISSIMILARITY_T30TXK.tmp.tif A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01DISSIMILARITY_T30TXK.tif\n",
      "Creating output file that is 4392P x 4392L.\n",
      "Processing A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01DISSIMILARITY_T30TXK.tmp.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      ">> gdal_translate -b 3 -a_nodata -9999.0 -of GTiff A:\\S2\\Deliverables\\Teruel\\T30TXK\\GLCM\\Teruel_20220000_GLCM_T30TXK.tif A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\Teruel_20220000_S2_B01HOMOGENEITY_T30TXK.tmp.tif\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 152\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SRC_GLCM:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[GLCM] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSRC_GLCM\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 152\u001b[0m     built \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m process_product(SRC_GLCM, plan_glcm)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m• No GLCM found — skipping\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 126\u001b[0m, in \u001b[0;36mprocess_product\u001b[1;34m(src_tif, plan_func)\u001b[0m\n\u001b[0;32m    124\u001b[0m tmp \u001b[38;5;241m=\u001b[39m dst\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tmp.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m     gdal_translate_band(src_tif, band_idx, tmp, NODATA)\n\u001b[0;32m    127\u001b[0m     gdal_warp_reproject(tmp, dst, TARGET_EPSG, NODATA, resample\u001b[38;5;241m=\u001b[39mresample)\n\u001b[0;32m    128\u001b[0m     created\u001b[38;5;241m.\u001b[39mappend(dst)\n",
      "Cell \u001b[1;32mIn[33], line 24\u001b[0m, in \u001b[0;36mgdal_translate_band\u001b[1;34m(src_tif, band_idx, tmp_tif, nodata)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgdal_translate_band\u001b[39m(src_tif: Path, band_idx: \u001b[38;5;28mint\u001b[39m, tmp_tif: Path, nodata\u001b[38;5;241m=\u001b[39mNODATA):\n\u001b[0;32m     16\u001b[0m     args \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgdal_translate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-b\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(band_idx),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mstr\u001b[39m(tmp_tif),\n\u001b[0;32m     23\u001b[0m     ]\n\u001b[1;32m---> 24\u001b[0m     run_cmd(args)\n",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m, in \u001b[0;36mrun_cmd\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_cmd\u001b[39m(args: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Pretty-print for logs\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args))\n\u001b[1;32m----> 7\u001b[0m     p \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(args, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# shell=False by default\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(p\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mstrip())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicate(\u001b[38;5;28minput\u001b[39m, endtime, timeout)\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1628\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remaining_time(endtime))\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1630\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[0;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === S2 DATA BUILDER: split -> name -> reproject (GDAL CLI), write inventory ===\n",
    "\n",
    "# ---- Helpers ----\n",
    "def run_cmd(args: list[str]):\n",
    "    # Pretty-print for logs\n",
    "    print(\">>\", \" \".join(args))\n",
    "    p = subprocess.run(args, text=True, capture_output=True)  # shell=False by default\n",
    "    if p.stdout.strip():\n",
    "        print(p.stdout.strip())\n",
    "    if p.returncode != 0:\n",
    "        if p.stderr.strip():\n",
    "            print(p.stderr.strip())\n",
    "        raise RuntimeError(\"Command failed\")\n",
    "\n",
    "def gdal_translate_band(src_tif: Path, band_idx: int, tmp_tif: Path, nodata=NODATA):\n",
    "    args = [\n",
    "        \"gdal_translate\",\n",
    "        \"-b\", str(band_idx),\n",
    "        \"-a_nodata\", str(nodata),\n",
    "        \"-of\", \"GTiff\",\n",
    "        str(src_tif),\n",
    "        str(tmp_tif),\n",
    "    ]\n",
    "    run_cmd(args)\n",
    "\n",
    "def gdal_warp_reproject(src_tif: Path, dst_tif: Path, epsg: str, nodata=NODATA, resample=\"bilinear\"):\n",
    "    args = [\n",
    "        \"gdalwarp\",\n",
    "        \"-overwrite\",\n",
    "        \"-t_srs\", epsg,\n",
    "        \"-srcnodata\", str(nodata),\n",
    "        \"-dstnodata\", str(nodata),\n",
    "        \"-r\", resample,\n",
    "        \"-multi\",\n",
    "        str(src_tif),\n",
    "        str(dst_tif),\n",
    "    ]\n",
    "    run_cmd(args)\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Where to read and write ----\n",
    "TROOT = DELIV  # already = ...\\SerraMafra\\T29SMD   (fixes duplication)\n",
    "OUT_BASE = TROOT / \"DATASET\"\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "INV_CSV  = OUT_BASE / f\"{fmt_tag(REGION_TAG, YEAR, 'S2_INVENTORY', TILE)}.csv\"\n",
    "ensure_dir(INV_CSV)\n",
    "\n",
    "# -- Robust discovery (prefer non-CLIP, fall back to CLIPPED / recursive) --\n",
    "def pick_prefer_unclipped(paths):\n",
    "    # sort so that unclipped come first; if both exist, we use the first\n",
    "    return sorted(paths, key=lambda p: (\"_CLIP\" in p.stem, p.name))\n",
    "\n",
    "# S2TC\n",
    "S2TC_DIR = TROOT / \"S2TC\"\n",
    "s2tc_list = list(S2TC_DIR.glob(\"*.tif\"))\n",
    "if not s2tc_list:\n",
    "    s2tc_list = list(TROOT.rglob(\"*S2TC*.tif\"))\n",
    "s2tc_list = pick_prefer_unclipped(s2tc_list)\n",
    "SRC_S2TC = s2tc_list[0] if s2tc_list else None\n",
    "\n",
    "# BIO (per-date + BIOTC)\n",
    "BIO_DIR = TROOT / \"BIO\"\n",
    "bio_list = list(BIO_DIR.glob(\"*.tif\"))\n",
    "if not bio_list:\n",
    "    bio_list = list(TROOT.rglob(\"*BIO*.tif\"))\n",
    "# split composite vs per-date, keep stable order\n",
    "bio_tc   = [p for p in bio_list if re.search(r\"(S2BIOTC|_BIO25_TC)\", p.name, re.I)]\n",
    "bio_date = [p for p in bio_list if p not in bio_tc]\n",
    "bio_tc   = pick_prefer_unclipped(bio_tc)\n",
    "bio_date = pick_prefer_unclipped(bio_date)\n",
    "SRC_BIO  = bio_tc + bio_date  # process composite first, then dates\n",
    "\n",
    "# GLCM\n",
    "GLCM_DIR = TROOT / \"GLCM\"\n",
    "glcm_list = list(GLCM_DIR.glob(\"*.tif\"))\n",
    "if not glcm_list:\n",
    "    glcm_list = list(TROOT.rglob(\"*GLCM*.tif\"))\n",
    "glcm_list = pick_prefer_unclipped(glcm_list)\n",
    "SRC_GLCM = glcm_list[0] if glcm_list else None\n",
    "\n",
    "print(\"== S2 Data Builder ==\")\n",
    "print(\"• S2TC:\", [SRC_S2TC.name] if SRC_S2TC else [])\n",
    "print(\"• BIO_TC:\", [p.name for p in bio_tc])\n",
    "print(\"• BIO per-date:\", len(bio_date))\n",
    "print(\"• GLCM:\", [SRC_GLCM.name] if SRC_GLCM else [])\n",
    "\n",
    "# ---- Build splitting plans ----\n",
    "def plan_tc(src: Path):\n",
    "    return [(i, var, OUT_BASE / out_name(REGION_TAG, YEAR, PLATFORM, var, TILE), RESAMPLE_NUMERIC)\n",
    "            for i, var in enumerate(TC_DATASET_ORDER, start=1)]\n",
    "\n",
    "def plan_bio(src: Path):\n",
    "    is_tc = bool(re.search(r\"(S2BIOTC|_BIO25_TC)\", src.name, re.I))\n",
    "    order = BIO_TC_ORDER if is_tc else BIO_DT_ORDER\n",
    "    plan = []\n",
    "    for i, var in enumerate(order, start=1):\n",
    "        res = RESAMPLE_FLAGS if var.endswith(\"FLAGS\") else RESAMPLE_NUMERIC\n",
    "        plan.append((i, var, OUT_BASE / out_name(REGION_TAG, YEAR, PLATFORM, var, TILE), res))\n",
    "    return plan\n",
    "\n",
    "def plan_glcm(src: Path):\n",
    "    plan = []\n",
    "    band_idx = 1\n",
    "    for b in TC_DATASET_ORDER:                 # B01..B12\n",
    "        for stat in GLCM_STATS:        # 10 stats\n",
    "            var = f\"{b}{stat}\"         # e.g., B03DISSIMILARITY\n",
    "            plan.append((band_idx, var, OUT_BASE / out_name(REGION_TAG, YEAR, PLATFORM, var, TILE), RESAMPLE_NUMERIC))\n",
    "            band_idx += 1\n",
    "    return plan\n",
    "\n",
    "# ---- Execute split + reproject ----\n",
    "def process_product(src_tif: Path, plan_func):\n",
    "    if not src_tif or not src_tif.exists():\n",
    "        print(f\"• Missing: {src_tif} — skipping\")\n",
    "        return []\n",
    "    created = []\n",
    "    for band_idx, var, dst, resample in plan_func(src_tif):\n",
    "        if dst.exists():\n",
    "            print(f\"• Skip (exists): {dst.name}\")\n",
    "            created.append(dst)\n",
    "            continue\n",
    "        tmp = dst.with_suffix(\".tmp.tif\")\n",
    "        try:\n",
    "            gdal_translate_band(src_tif, band_idx, tmp, NODATA)\n",
    "            gdal_warp_reproject(tmp, dst, TARGET_EPSG, NODATA, resample=resample)\n",
    "            created.append(dst)\n",
    "        finally:\n",
    "            try: tmp.unlink()\n",
    "            except Exception: pass\n",
    "    return created\n",
    "\n",
    "# ---- Run for S2TC, BIO (per-date + TC), GLCM ----\n",
    "built = []\n",
    "\n",
    "if SRC_S2TC:\n",
    "    print(f\"[S2TC] {SRC_S2TC.name}\")\n",
    "    built += process_product(SRC_S2TC, plan_tc)\n",
    "else:\n",
    "    print(\"• No S2TC found — skipping\")\n",
    "\n",
    "if SRC_BIO:\n",
    "    for bio_tif in SRC_BIO:\n",
    "        print(f\"[BIO] {bio_tif.name}\")\n",
    "        built += process_product(bio_tif, plan_bio)\n",
    "else:\n",
    "    print(\"• No BIO tifs found — skipping\")\n",
    "\n",
    "if SRC_GLCM:\n",
    "    print(f\"[GLCM] {SRC_GLCM.name}\")\n",
    "    built += process_product(SRC_GLCM, plan_glcm)\n",
    "else:\n",
    "    print(\"• No GLCM found — skipping\")\n",
    "\n",
    "# ---- Inventory CSV ----\n",
    "rows = []\n",
    "for p in sorted(set(built)):\n",
    "    # StudyArea_YYYY0000_S2_<VAR>_<TILE>.tif\n",
    "    parts = p.stem.split(\"_\")\n",
    "    var = parts[-2] if len(parts) >= 2 else \"UNKNOWN\"\n",
    "    rows.append([REGION_TAG, YEAR, PLATFORM, TILE, var, str(p)])\n",
    "\n",
    "with open(INV_CSV, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"study_area\",\"year\",\"platform\",\"tile\",\"variable\",\"path\"])\n",
    "    w.writerows(rows)\n",
    "\n",
    "print(f\"\\n✓ Dataset ready in {OUT_BASE}\")\n",
    "print(f\"  • Singles written: {len(rows)}\")\n",
    "print(f\"  • Inventory: {INV_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dccaa114-4ab0-4e9b-b47c-e4a050347a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== CLEANUP PLAN ==\n",
      "PUBLISH_MODE = release\n",
      "\n",
      "[WORK] Will DELETE dirs:\n",
      "  [DIR] A:\\S2\\work\\Teruel\\T30TXK\\REF25\n",
      "  [DIR] A:\\S2\\work\\Teruel\\T30TXK\\BIO25\n",
      "  [DIR] A:\\S2\\work\\Teruel\\T30TXK\\SCL25\n",
      "  [DIR] A:\\S2\\work\\Teruel\\T30TXK\\COMPOSITE25\n",
      "  [DIR] A:\\S2\\work\\Teruel\\T30TXK\\GLCM25\n",
      "  [DIR] A:\\S2\\work\\Teruel\\T30TXK\\BIO_TC\n",
      "  [DIR] A:\\S2\\work\\Teruel\\T30TXK\\COLLOC\n",
      "  [DIR] A:\\S2\\work\\Teruel\\T30TXK\\_graphs\n",
      "[WORK] Will DELETE files:\n",
      "\n",
      "[DELIV] Will DELETE dirs:\n",
      "  [DIR] A:\\S2\\Deliverables\\Teruel\\T30TXK\\S2TC\n",
      "  [DIR] A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\n",
      "  [DIR] A:\\S2\\Deliverables\\Teruel\\T30TXK\\GLCM\n",
      "  [DIR] A:\\S2\\Deliverables\\Teruel\\T30TXK\\PCA\n",
      "\n",
      "Must-have check:\n",
      "  DATASET_DIR : OK  -> A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\n",
      "  README      : OK  -> A:\\S2\\Deliverables\\Teruel\\T30TXK\\DATASET\\README_bandmap.txt\n",
      "🧹 [WORK] rmtree: A:\\S2\\work\\Teruel\\T30TXK\\REF25\n",
      "🧹 [WORK] rmtree: A:\\S2\\work\\Teruel\\T30TXK\\BIO25\n",
      "🧹 [WORK] rmtree: A:\\S2\\work\\Teruel\\T30TXK\\SCL25\n",
      "🧹 [WORK] rmtree: A:\\S2\\work\\Teruel\\T30TXK\\COMPOSITE25\n",
      "🧹 [WORK] rmtree: A:\\S2\\work\\Teruel\\T30TXK\\GLCM25\n",
      "🧹 [WORK] rmtree: A:\\S2\\work\\Teruel\\T30TXK\\BIO_TC\n",
      "🧹 [WORK] rmtree: A:\\S2\\work\\Teruel\\T30TXK\\COLLOC\n",
      "🧹 [WORK] rmtree: A:\\S2\\work\\Teruel\\T30TXK\\_graphs\n",
      "🧹 [DELIV] rmtree: A:\\S2\\Deliverables\\Teruel\\T30TXK\\S2TC\n",
      "🧹 [DELIV] rmtree: A:\\S2\\Deliverables\\Teruel\\T30TXK\\BIO\n",
      "🧹 [DELIV] rmtree: A:\\S2\\Deliverables\\Teruel\\T30TXK\\GLCM\n",
      "🧹 [DELIV] rmtree: A:\\S2\\Deliverables\\Teruel\\T30TXK\\PCA\n",
      "\n",
      "✅ Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "# Final cleanup: obey PUBLISH_MODE\n",
    "# - Always clean intermediates under work/<PLOT>/<TILE>/\n",
    "# - In release mode: prune deliverables to keep only DATASET/\n",
    "\n",
    "WORK_ROOT = Path(r\"A:\\S2\\work\")\n",
    "D_ROOT    = Path(r\"A:\\S2\\Deliverables\")\n",
    "\n",
    "# Safety switches\n",
    "DRY_RUN          = False   # True = preview only\n",
    "ALLOW_IF_PARTIAL = False   # True = ignore missing must-haves\n",
    "\n",
    "# ---- Deliverables root for this tile ----\n",
    "D_TILE = DELIV\n",
    "DATASET_DIR = D_TILE / \"DATASET\"\n",
    "\n",
    "# ---- Must-have gate (release integrity) ----\n",
    "must_have = {\n",
    "    \"DATASET_DIR\": DATASET_DIR,\n",
    "    \"README\":      DATASET_DIR / \"README_bandmap.txt\",\n",
    "}\n",
    "\n",
    "missing_must = [k for k, p in must_have.items() if not p.exists()]\n",
    "if missing_must and not ALLOW_IF_PARTIAL:\n",
    "    print(\"⚠️ Cleanup aborted: required release artifacts missing:\")\n",
    "    for k in missing_must:\n",
    "        print(f\"  - {k}: {must_have[k]}\")\n",
    "    print(\"Set ALLOW_IF_PARTIAL=True if you still want to proceed.\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# =====================================================================\n",
    "# WORK cleanup (always)\n",
    "# =====================================================================\n",
    "work_tile = WORK_ROOT / PLOT / TILE\n",
    "\n",
    "rm_work_dirs = [\n",
    "    work_tile / \"REF25\",\n",
    "    work_tile / \"BIO25\",\n",
    "    work_tile / \"SCL25\",\n",
    "    work_tile / \"COMPOSITE25\",\n",
    "    work_tile / \"GLCM25\",\n",
    "    work_tile / \"DEBUG\",\n",
    "    work_tile / \"BIO_TC\",\n",
    "    work_tile / \"COLLOC\",\n",
    "    work_tile / \"_graphs\",\n",
    "]\n",
    "\n",
    "rm_work_files = list(work_tile.glob(\"*.tmp\")) + list(work_tile.glob(\"*.log\"))\n",
    "\n",
    "# =====================================================================\n",
    "# DELIVERABLE pruning (depends on PUBLISH_MODE)\n",
    "# =====================================================================\n",
    "KEEP_TILE_DIRS = {\n",
    "    \"dev\":     {\"S2TC\", \"BIO\", \"GLCM\", \"DATASET\"},\n",
    "    \"release\": {\"DATASET\"},\n",
    "}[PUBLISH_MODE]\n",
    "\n",
    "# Delete any directory in D_TILE that isn't in KEEP_TILE_DIRS\n",
    "rm_deliv_dirs = [p for p in D_TILE.iterdir() if p.is_dir() and p.name not in KEEP_TILE_DIRS]\n",
    "\n",
    "# Optional: also delete stray files at tile root (release)\n",
    "rm_deliv_files = []\n",
    "if PUBLISH_MODE == \"release\":\n",
    "    rm_deliv_files = [p for p in D_TILE.iterdir() if p.is_file()]\n",
    "\n",
    "# =====================================================================\n",
    "# PRINT PLAN\n",
    "# =====================================================================\n",
    "print(\"\\n== CLEANUP PLAN ==\")\n",
    "print(f\"PUBLISH_MODE = {PUBLISH_MODE}\")\n",
    "\n",
    "print(\"\\n[WORK] Will DELETE dirs:\")\n",
    "for d in rm_work_dirs:\n",
    "    if d.exists(): print(\"  [DIR]\", d)\n",
    "\n",
    "print(\"[WORK] Will DELETE files:\")\n",
    "for f in rm_work_files:\n",
    "    if f.exists(): print(\"  [FIL]\", f)\n",
    "\n",
    "print(\"\\n[DELIV] Will DELETE dirs:\")\n",
    "for d in rm_deliv_dirs:\n",
    "    if d.exists(): print(\"  [DIR]\", d)\n",
    "\n",
    "print(\"[DELIV] Will DELETE files:\")\n",
    "for f in rm_deliv_files:\n",
    "    if f.exists(): print(\"  [FIL]\", f)\n",
    "\n",
    "print(\"\\nMust-have check:\")\n",
    "for k, p in must_have.items():\n",
    "    print(f\"  {k:12s}: {'OK' if p.exists() else 'MISSING'}  -> {p}\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXECUTION\n",
    "# =====================================================================\n",
    "if DRY_RUN:\n",
    "    print(\"\\nDRY_RUN=True — no deletions performed.\")\n",
    "else:\n",
    "    def safe_rmtree(path: Path, root: Path):\n",
    "        path = path.resolve()\n",
    "        root = root.resolve()\n",
    "        if root not in path.parents and path != root:\n",
    "            raise RuntimeError(f\"Refusing to delete outside root={root}: {path}\")\n",
    "        shutil.rmtree(path, ignore_errors=True)\n",
    "\n",
    "    def safe_unlink(path: Path, root: Path):\n",
    "        path = path.resolve()\n",
    "        root = root.resolve()\n",
    "        if root not in path.parents and path != root:\n",
    "            raise RuntimeError(f\"Refusing to delete outside root={root}: {path}\")\n",
    "        try:\n",
    "            path.unlink()\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    # ---- WORK ----\n",
    "    for d in rm_work_dirs:\n",
    "        if d.exists():\n",
    "            print(\"🧹 [WORK] rmtree:\", d)\n",
    "            safe_rmtree(d, WORK_ROOT)\n",
    "\n",
    "    for f in rm_work_files:\n",
    "        if f.exists():\n",
    "            print(\"🧽 [WORK] unlink:\", f)\n",
    "            safe_unlink(f, WORK_ROOT)\n",
    "\n",
    "    # ---- DELIVERABLES ----\n",
    "    for d in rm_deliv_dirs:\n",
    "        if d.exists():\n",
    "            print(\"🧹 [DELIV] rmtree:\", d)\n",
    "            safe_rmtree(d, D_ROOT)\n",
    "\n",
    "    for f in rm_deliv_files:\n",
    "        if f.exists():\n",
    "            print(\"🧽 [DELIV] unlink:\", f)\n",
    "            safe_unlink(f, D_ROOT)\n",
    "\n",
    "    print(\"\\n✅ Cleanup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1ef22-7e46-4b9a-8f81-ba875c3e4ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
